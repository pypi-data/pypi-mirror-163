# Makefile for python interface for package tokenizer.
# File is generated by gopy. Do not edit.
# gopy build -output=tokenizer -vm=/opt/python/cp38-cp38/bin/python github.com/cohere-ai/tokenizer

GOCMD=go
GOBUILD=$(GOCMD) build -mod=mod
GOIMPORTS=goimports
PYTHON=/opt/python/cp38-cp38/bin/python
LIBEXT=.so

# get the CC and flags used to build python:
GCC = $(shell $(GOCMD) env CC)
CFLAGS = -I/opt/python/cp38-cp38/include/python3.8
LDFLAGS = -L/opt/_internal/cpython-3.8.13/lib -lpython3.8 -lcrypt -lpthread -ldl  -lutil -lm -lm

all: gen build

gen:
	gopy gen -no-make -vm=/opt/python/cp38-cp38/bin/python github.com/cohere-ai/tokenizer

build:
	# build target builds the generated files -- this is what gopy build does..
	# this will otherwise be built during go build and may be out of date
	- rm tokenizer.c
	# goimports is needed to ensure that the imports list is valid
	$(GOIMPORTS) -w tokenizer.go
	# generate tokenizer_go$(LIBEXT) from tokenizer.go -- the cgo wrappers to go functions
	$(GOBUILD) -buildmode=c-shared -o tokenizer_go$(LIBEXT) tokenizer.go
	# use pybindgen to build the tokenizer.c file which are the CPython wrappers to cgo wrappers..
	# note: pip install pybindgen to get pybindgen if this fails
	$(PYTHON) build.py
	# build the _tokenizer$(LIBEXT) library that contains the cgo and CPython wrappers
	# generated tokenizer.py python wrapper imports this c-code package
	
	$(GCC) tokenizer.c  tokenizer_go$(LIBEXT) -o _tokenizer$(LIBEXT) $(CFLAGS) $(LDFLAGS) -fPIC --shared -w
	


