{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Marketdata Files\n",
    "\n",
    "This notebook shows an example of processing a set of market data files into trades, quotes and open interest records using multiple processes to utilize all the cores on your machine.\n",
    "\n",
    "It uses the marketdata_processor and pyqstrat_cpp submodules of pyqstrat.  pyqstrat_cpp contains functionality written in C++ since I use this for processing large tick data files, which can be hundreds of gigabytes and would take too long to process in Python.\n",
    "\n",
    "Here are the stages we will go through.\n",
    "\n",
    "1.  File discovery : Generating the list of files we need to process\n",
    "2.  Decompressing and Reading Files : pyqstrat can handle zip, gzip, bz2 and xz files\n",
    "3.  Filtering: Discard any records we don't care about or that are clearly in error\n",
    "3.  Parsing : Parsing lines from the file into quotes, trades or open interest records\n",
    "4.  Cleaning : For example, some vendors use 0 to indicate there was no bid. We can replace these 0's with NaN for easier downstream processing.\n",
    "5.  Aggregation : Aggregate quotes and trades in various ways, for example, aggregate into 1 minute bars or into instantaneous top of book records.\n",
    "6.  Writing: Finally we write the aggregated data to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T22:02:34.607070Z",
     "start_time": "2018-10-15T22:02:34.563021Z"
    }
   },
   "source": [
    "## Test Data Creation\n",
    "\n",
    "First, lets create some data.  We will create a few files in the temp directory representing data that a market data vendor would have sent us.  This data is options data formatted like a real vendor's options data files but the actual prices and quantities are not real.  We will create a gzipped file with some open interest, quote and trade records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T02:39:28.716402Z",
     "start_time": "2022-08-16T02:39:28.425567Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Type</th>\n",
       "      <th>Side</th>\n",
       "      <th>Info</th>\n",
       "      <th>PutCall</th>\n",
       "      <th>Expiration</th>\n",
       "      <th>Strike</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Premium</th>\n",
       "      <th>Exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06:30:31.461</td>\n",
       "      <td>SPXW</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>20160316</td>\n",
       "      <td>21000000</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06:30:31.461</td>\n",
       "      <td>SPXW</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P</td>\n",
       "      <td>20160316</td>\n",
       "      <td>20700000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06:30:31.461</td>\n",
       "      <td>SPXW</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>20160316</td>\n",
       "      <td>19750000</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06:30:31.461</td>\n",
       "      <td>SPXW</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>20160316</td>\n",
       "      <td>19600000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06:30:31.461</td>\n",
       "      <td>SPXW</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>20160316</td>\n",
       "      <td>19450000</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>09:30:03.566</td>\n",
       "      <td>BRKA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sample Info</td>\n",
       "      <td>P</td>\n",
       "      <td>20160316</td>\n",
       "      <td>19500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>09:30:03.568</td>\n",
       "      <td>BRKA</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "      <td>Sample Info 2</td>\n",
       "      <td>P</td>\n",
       "      <td>20160316</td>\n",
       "      <td>19700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>09:30:05.886</td>\n",
       "      <td>BRKA</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "      <td>Sample Info 3</td>\n",
       "      <td>C</td>\n",
       "      <td>20160316</td>\n",
       "      <td>20550000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>09:30:05.886</td>\n",
       "      <td>BRKA</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "      <td>Sample Info 4</td>\n",
       "      <td>P</td>\n",
       "      <td>20160316</td>\n",
       "      <td>19750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>09:30:05.886</td>\n",
       "      <td>BRKA</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "      <td>Sample Info 5</td>\n",
       "      <td>P</td>\n",
       "      <td>20160316</td>\n",
       "      <td>20150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp Ticker Type Side           Info PutCall  Expiration  \\\n",
       "0   06:30:31.461   SPXW    O                           C    20160316   \n",
       "1   06:30:31.461   SPXW    O                           P    20160316   \n",
       "2   06:30:31.461   SPXW    O                           C    20160316   \n",
       "3   06:30:31.461   SPXW    O                           C    20160316   \n",
       "4   06:30:31.461   SPXW    O                           C    20160316   \n",
       "..           ...    ...  ...  ...            ...     ...         ...   \n",
       "71  09:30:03.566   BRKA              Sample Info       P    20160316   \n",
       "72  09:30:03.568   BRKA    X       Sample Info 2       P    20160316   \n",
       "73  09:30:05.886   BRKA    X       Sample Info 3       C    20160316   \n",
       "74  09:30:05.886   BRKA    X       Sample Info 4       P    20160316   \n",
       "75  09:30:05.886   BRKA    X       Sample Info 5       P    20160316   \n",
       "\n",
       "      Strike  Quantity  Premium Exchange  \n",
       "0   21000000    1029.0      0.0        W  \n",
       "1   20700000       5.0      0.0        W  \n",
       "2   19750000     205.0      0.0        W  \n",
       "3   19600000     320.0      0.0        W  \n",
       "4   19450000     256.0      0.0        W  \n",
       "..       ...       ...      ...      ...  \n",
       "71  19500000       NaN      NaN        W  \n",
       "72  19700000       NaN      NaN        W  \n",
       "73  20550000       NaN      NaN        W  \n",
       "74  19750000       NaN      NaN        W  \n",
       "75  20150000       NaN      NaN        W  \n",
       "\n",
       "[76 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "import pyqstrat as pq\n",
    "import tempfile\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "open_interest_records = \\\n",
    "b'''Timestamp,Ticker,Type,Side,Info,PutCall,Expiration,Strike,Quantity,Premium,Exchange\n",
    "06:30:31.461,SPXW,O, , ,C,20160316,21000000,1029,0,W\n",
    "06:30:31.461,SPXW,O, , ,P,20160316,20700000,5,0,W\n",
    "06:30:31.461,SPXW,O, , ,C,20160316,19750000,205,0,W\n",
    "06:30:31.461,SPXW,O, , ,C,20160316,19600000,320,0,W\n",
    "06:30:31.461,SPXW,O, , ,C,20160316,19450000,256,0,W\n",
    "06:30:31.461,SPXW,O, , ,C,20160316,19300000,9,0,W\n",
    "06:30:31.461,SPXW,O, , ,C,20160316,19150000,3,0,W\n",
    "06:30:31.461,SPXW,O, , ,C,20160316,19000000,253,0,W\n",
    "06:30:31.461,SPXW,O, , ,C,20160316,18850000,5,0,W\n",
    "06:30:31.462,SPXW,O, , ,P,20160316,18650000,194,0,W\n",
    "06:30:31.463,SPXW,O, , ,P,20160316,18350000,722,0,W\n",
    "06:30:31.463,SPXW,O, , ,P,20160316,18200000,204,0,W\n",
    "06:30:31.463,SPXW,O, , ,C,20160316,20450000,690,0,W\n",
    "06:30:31.463,SPXW,O, , ,P,20160316,20250000,498,0,W\n",
    "06:30:31.463,SPXW,O, , ,C,20160316,20050000,559,0,W\n",
    "06:30:31.464,SPXW,O, , ,C,20160316,19900000,530,0,W\n",
    "'''\n",
    "\n",
    "quote_records = \\\n",
    "b'''10:19:12.950,BRKA,F,O, ,C,20160316,20450000,115,15500,W\n",
    "10:19:13.140,BRKA,F,O, ,C,20160316,20300000,85,49000,W\n",
    "10:19:13.140,BRKA,F,B, ,C,20160316,20300000,38,45000,W\n",
    "10:19:13.140,BRKA,F,O, ,C,20160316,20350000,87,34000,W\n",
    "10:19:13.140,BRKA,F,B, ,C,20160316,20350000,44,31000,W\n",
    "10:19:13.140,BRKA,F,O, ,C,20160316,20100000,48,143000,W\n",
    "10:19:13.140,BRKA,F,B, ,C,20160316,20100000,30,136000,W\n",
    "10:19:13.141,BRKA,F,O, ,P,20160316,20150000,32,120000,W\n",
    "10:19:13.141,BRKA,F,B, ,P,20160316,20150000,55,112000,W\n",
    "10:19:13.141,BRKA,F,O, ,P,20160316,20050000,51,78000,W\n",
    "10:19:13.141,BRKA,F,B, ,P,20160316,20050000,28,73000,W\n",
    "10:19:13.141,BRKA,F,O, ,P,20160316,20250000,14,175000,W\n",
    "10:19:13.141,BRKA,F,B, ,P,20160316,20250000,21,161000,W\n",
    "10:19:13.141,BRKA,F,O, ,P,20160316,20200000,15,145000,W\n",
    "10:19:13.141,BRKA,F,B, ,P,20160316,20200000,42,136000,W\n",
    "10:20:13.152,BRKA,F,O, ,C,20160316,20050000,24,179000,W\n",
    "10:20:13.152,BRKA,F,B, ,C,20160316,20450000,18,165000,W\n",
    "10:20:13.152,BRKA,F,O, ,C,20160316,20300000,85,49000,W\n",
    "10:20:13.152,BRKA,F,B, ,C,20160316,20300000,28,45000,W\n",
    "10:20:13.160,BRKA,F,O, ,C,20160316,20100000,52,143000,W\n",
    "10:20:13.160,BRKA,F,B, ,C,20160316,20100000,30,136000,W\n",
    "10:20:13.161,BRKA,F,O, ,C,20160316,20300000,85,49000,W\n",
    "10:20:13.161,BRKA,F,B, ,C,20160316,20300000,32,45000,W\n",
    "10:20:13.161,BRKA,F,O, ,P,20160316,20050000,55,78000,W\n",
    "10:20:13.161,BRKA,F,B, ,P,20160316,20050000,28,73000,W\n",
    "10:20:13.161,BRKA,F,O, ,P,20160316,20100000,20,96000,W\n",
    "10:20:13.161,BRKA,F,B, ,P,20160316,20100000,48,91000,W\n",
    "10:20:13.161,BRKA,F,O, ,P,20160316,20150000,36,120000,W\n",
    "10:20:13.161,BRKA,F,B, ,P,20160316,20150000,59,112000,W\n",
    "'''\n",
    "\n",
    "trade_records = \\\n",
    "b'''09:30:03.365,BRKA,T, , ,C,20160316,20200000,1,98000,W\n",
    "09:30:03.481,BRKA,T, , ,P,20160316,20650000,2,442000,W\n",
    "09:30:03.566,BRKA,T, ,L,P,20160316,20650000,1,6000,W\n",
    "09:30:03.568,BRKA,T, ,L,P,20160316,20650000,2,13500,W\n",
    "09:30:03.568,BRKA,T, ,L,P,20160316,19900000,1,34000,W\n",
    "09:30:04.473,BRKA,T, ,L,C,20160316,19450000,15,714000,W\n",
    "09:30:05.883,BRKA,T, ,L,C,20160316,20400000,4,24000,W\n",
    "09:30:05.884,BRKA,T, ,L,P,20160316,20100000,10,87500,W\n",
    "09:30:05.884,BRKA,T, ,L,P,20160316,20150000,10,109000,W\n",
    "09:30:05.886,BRKA,T, ,L,C,20160316,20150000,3,119000,W\n",
    "09:30:05.886,BRKA,T, ,L,C,20160316,20550000,3,7000,W\n",
    "09:30:05.886,BRKA,T, ,L,P,20160316,19750000,3,15000,W\n",
    "09:30:05.886,BRKA,T, ,L,P,20160316,20150000,3,110500,W\n",
    "09:31:09.285,BRKA,T, ,L,P,20160316,20650000,10,26000,W\n",
    "09:31:09.286,BRKA,T, ,L,P,20160316,20650000,10,33500,W\n",
    "09:31:11.491,BRKA,T, , ,P,20160316,20650000,24,28000,W\n",
    "09:31:11.586,BRKA,T, , ,P,20160316,19850000,12,28000,W\n",
    "09:31:12.805,BRKA,T, , ,P,20160316,19800000,34,22000,W\n",
    "09:31:12.831,BRKA,T, , ,P,20160316,19750000,44,17500,W\n",
    "09:31:12.863,BRKA,T, , ,P,20160316,19750000,13,17500,W\n",
    "09:31:13.640,BRKA,T, , ,P,20160316,19850000,1,28000,W\n",
    "09:31:18.232,BRKA,T, ,L,C,20160316,20350000,26,34000,W\n",
    "09:31:18.232,BRKA,T, ,L,C,20160316,20400000,26,23000,W\n",
    "09:31:19.176,BRKA,T, ,L,P,20160316,19200000,3,3000,W\n",
    "09:31:19.176,BRKA,T, ,L,P,20160316,19300000,3,3500,W\n",
    "09:31:21.639,BRKA,T, ,L,C,20160316,20350000,4,34000,W\n",
    "'''\n",
    "\n",
    "other_records = \\\n",
    "b'''09:30:03.566,BRKA, , ,Sample Info,P,20160316,19500000,,,W\n",
    "09:30:03.568,BRKA,X, ,Sample Info 2,P,20160316,19700000,,,W\n",
    "09:30:05.886,BRKA,X, ,Sample Info 3,C,20160316,20550000,,,W\n",
    "09:30:05.886,BRKA,X, ,Sample Info 4,P,20160316,19750000,,,W\n",
    "09:30:05.886,BRKA,X, ,Sample Info 5,P,20160316,20150000,,,W\n",
    "'''\n",
    "if os.path.isdir('/tmp'):\n",
    "    temp_dir = \"/tmp/\"\n",
    "else:\n",
    "    temp_dir =  tempfile.gettempdir()\n",
    "    \n",
    "input_filename = temp_dir + '/BRKA_2018-01-01_data'\n",
    "    \n",
    "from sys import platform\n",
    "if platform not in [\"win32\", \"cygwin\"]: # cannot read compressed files on windows yet because of link issues with boost\n",
    "    input_filename += '.gz'\n",
    "    import gzip\n",
    "    with gzip.open(input_filename, 'wb') as f:\n",
    "        f.write(open_interest_records + quote_records + trade_records + other_records)\n",
    "else:\n",
    "    with open(input_filename, 'w') as f:\n",
    "        f.write((open_interest_records + quote_records + trade_records + other_records).decode('utf-8'))\n",
    "    \n",
    "# Look at the data\n",
    "import pandas as pd\n",
    "pd.read_csv(input_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T22:08:08.665014Z",
     "start_time": "2018-10-15T22:08:08.658946Z"
    }
   },
   "source": [
    "## File discovery\n",
    "\n",
    "We use the helper function object PathFileNameProvider to generate the list of files we need to process.\n",
    "<br>\n",
    "<br>\n",
    "We then use the helper function object SingleDirectoryFileNameMapper to figure out the output file name corresponding to each input file.  We will write output files with the same prefix\n",
    "as their corresponding input files but in a subdirectory called pyqstrat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T02:39:28.719680Z",
     "start_time": "2022-08-16T02:39:28.717588Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "file_path = temp_dir + '/BRKA_*'\n",
    "\n",
    "if platform not in [\"win32\", \"cygwin\"]: # cannot read compressed files on windows yet because of link issues with boost\n",
    "    file_path += '.gz'\n",
    "\n",
    "input_filename_provider = pq.PathFileNameProvider(file_path)\n",
    "output_dir = temp_dir + '/pyqstrat'\n",
    "if not os.path.isdir(output_dir): os.mkdir(output_dir)\n",
    "output_file_prefix_mapper = pq.SingleDirectoryFileNameMapper(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "Lets first create the functions that let us know if a record is a trade, quote or open interest record.  We know the second field in the input file contains the type of record.  We will also create a function that will let us quickly discard any lines we don't care about before we start parsing them.  We can also use a record filter that will filter out trade records after they have been parsed for more fine grained filtering, but we don't need it here, so we let the record filter default to None.\n",
    "\n",
    "We implement IsOther differently than the other functions to show how we can write a function in Python and plug it into the processing instead of using the predefined C++ functions. This will be much slower than using C++ functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T02:39:28.722930Z",
     "start_time": "2022-08-16T02:39:28.720457Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "is_quote = pq.IsFieldInList(2, [\"F\", \"N\"])\n",
    "is_trade = pq.IsFieldInList(2, [\"T\"])\n",
    "is_open_interest = pq.IsFieldInList(2, [\"O\"])\n",
    "\n",
    "# Show how a function can be implemented in python instead of using the pyqstrat C++ predefined functions\n",
    "class PyIsFieldInList(pq.CheckFields):\n",
    "    # The following line is necessary due to the way pybind11 calls virtual functions.  \n",
    "    # See #https://pybind11.readthedocs.io/en/stable/advanced/classes.html\n",
    "    def __init__(self, field_idx, flags):\n",
    "        pq.CheckFields.__init__(self) \n",
    "        self.field_idx = field_idx\n",
    "        self.flags = flags\n",
    "        \n",
    "    def __call__(self, fields):\n",
    "        return fields[self.field_idx] in self.flags\n",
    "    \n",
    "is_other = PyIsFieldInList(2, [\"X\"])\n",
    "\n",
    "# Keep only the lines that contain one of these substrings.  We can also use pq.RegExLineFilter but that is much slower than checking for substrings\n",
    "line_filter = pq.SubStringLineFilter([\",T,\", \",F,\", \",N,\", \",O,\", \",X,\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "Lets now create functions that create parsers.  We are going to use the helper function objects TextQuoteParser, TextTradeParser, TextOpenInterestParser, TextOtherParser that create the corresponding types from a record in the file.  These are designed for compressed or uncompressed text files where price, qty, etc. are stored in delimited fields.  If that is not the case for your market data files, you will have to create your own parsers.  These function objects are written in C++ for performance.\n",
    "\n",
    "We use the helper function FixedWidthParser which parses timestamps that have a fixed place for years, months, days, hours, minutes, seconds, milliseconds or microsedonds\n",
    "\n",
    "By default the system uses the helper function object PrintBadLineHandler for records that cannot be parsed.  This class prints out unparseable lines for debugging, or raises an Exception, depending on how its initialized.  You can implement your own handler for second chance, slower parsing of more complex records.\n",
    "\n",
    "By default, the sytem also uses the helper function price_qty_missing_data_handler to set prices and quantities that are 0 to NAN.  You can implement your own function object for other policies to deal with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T02:39:28.729386Z",
     "start_time": "2022-08-16T02:39:28.724135Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "time_parser = pq.FixedWidthTimeParser(micros = False, hours_start = 0, hours_size = 2, minutes_start = 3, minutes_size = 2, seconds_start = 6, seconds_size = 2, \n",
    "                                     millis_start = 9, millis_size = 3)\n",
    "\n",
    "def create_quote_parser(base_date, headers):\n",
    "    timestamp_idx = headers.index('timestamp')\n",
    "    qty_idx = headers.index('quantity')\n",
    "    price_idx = headers.index('premium')\n",
    "    bid_offer_idx = headers.index('side')\n",
    "    # Id indices are used to uniquely identify an instrument.  Within this file, put/call, epxiry and strike uniquely identify an option\n",
    "    id_indices = pq.get_field_indices(['putcall', 'expiration', 'strike'], headers)\n",
    "    # Any other info besides qty, price, bid/offer and id that we want to store is stored in the meta field\n",
    "    meta_indices = pq.get_field_indices(['info', 'exchange'], headers)\n",
    "    # Prices in the input file are stored in thousands of cents so we divide them by 10000.0 to get dollars.\n",
    "    # Bids are stored as \"O\" and offers are stored as \"O\"\n",
    "    return pq.TextQuoteParser(is_quote, base_date, [timestamp_idx], bid_offer_idx, price_idx, qty_idx, id_indices, meta_indices,\n",
    "                              [time_parser], \"B\", \"O\", 10000.0)\n",
    "                                 \n",
    "def create_trade_parser(base_date, headers):\n",
    "    timestamp_idx = headers.index('timestamp')\n",
    "    qty_idx = headers.index('quantity')\n",
    "    price_idx = headers.index('premium')\n",
    "    id_indices = pq.get_field_indices(['putcall', 'expiration', 'strike'], headers)\n",
    "    meta_indices = pq.get_field_indices(['info', 'exchange'], headers)\n",
    "    return pq.TextTradeParser(is_trade, base_date, [timestamp_idx], price_idx, qty_idx, id_indices, meta_indices,\n",
    "                                    [time_parser], 10000.0)\n",
    "                                 \n",
    "def create_open_interest_parser(base_date, headers):\n",
    "    timestamp_idx = headers.index('timestamp')\n",
    "    qty_idx = headers.index('quantity')\n",
    "    id_indices = pq.get_field_indices(['putcall', 'expiration', 'strike'], headers)\n",
    "    meta_indices = pq.get_field_indices(['info', 'exchange'], headers)\n",
    "    return pq.TextOpenInterestParser(is_open_interest, base_date, [timestamp_idx], qty_idx, id_indices, meta_indices,\n",
    "                                    [time_parser], 10000.0)\n",
    "                           \n",
    "def create_other_parser(base_date, headers):\n",
    "    timestamp_idx = headers.index('timestamp')\n",
    "    qty_idx = headers.index('quantity')\n",
    "    id_indices = pq.get_field_indices(['putcall', 'expiration', 'strike'], headers)\n",
    "    meta_indices = pq.get_field_indices(['info', 'exchange'], headers)\n",
    "    return pq.TextOtherParser(is_other, base_date, [timestamp_idx], id_indices, meta_indices, [time_parser])\n",
    "    \n",
    "def create_record_parser(base_date, headers):\n",
    "    return pq.TextRecordParser([create_quote_parser(base_date, headers), \n",
    "                                create_trade_parser(base_date, headers), \n",
    "                                create_open_interest_parser(base_date, headers), \n",
    "                                create_other_parser(base_date, headers)], \n",
    "                               exclusive = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "We have a choice on how we want to aggregate these records.  We will use the helper class QuoteTOBAggregator which creates top-of-book quotes at a given frequency (or for all ticks if frequency is omitted) and TradeBarAggregator which creates trade bars at given freqency.  For Open Interest and OtherRecords, we keep all records.  You can use None for any of these functions if you only care about parsing Trades, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T02:39:28.731639Z",
     "start_time": "2022-08-16T02:39:28.729997Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def create_aggregators(writer_creator, frequency = '1m'):\n",
    "    quote_agg = pq.QuoteTOBAggregator(writer_creator, frequency = frequency)\n",
    "    trade_bar_agg = pq.TradeBarAggregator(writer_creator, frequency = frequency)\n",
    "    open_interest_agg = pq.AllOpenInterestAggregator(writer_creator)\n",
    "    other_agg = pq.AllOtherAggregator(writer_creator)\n",
    "    return [quote_agg, trade_bar_agg, open_interest_agg, other_agg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing\n",
    "\n",
    "By default pyqstrat writes files using the HDF5 format for speed of reading and writing.  See https://www.hdfgroup.org/solutions/hdf5/ for more about HDF5. You can change the writing format by setting the argument writer_creator to a function that creates your own class implementing the pyqstrat Writer interface.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finishing Up\n",
    "\n",
    "We are now ready to run the process.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def process(input_filename, compression):\n",
    "    output_prefix = output_file_prefix_mapper(input_filename)\n",
    "    writer_creator = pq.HDF5WriterCreator(output_prefix, ' ')\n",
    "    pq.process_marketdata_file(\n",
    "        input_filename,\n",
    "        compression,\n",
    "        output_file_prefix_mapper, \n",
    "        create_record_parser,\n",
    "        create_aggregators,\n",
    "        line_filter, \n",
    "        pq.base_date_filename_mapper,\n",
    "        writer_creator = writer_creator)\n",
    "    writer_creator.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    done_file = output_dir + '/BRKA_2018-01-01_data.done'\n",
    "    if os.path.exists(done_file): os.remove(done_file)\n",
    "    with pq.ostream_redirect(stdout = True, stderr = True):\n",
    "        pq.process_marketdata(input_filename_provider, process, num_processes = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T00:35:45.764463Z",
     "start_time": "2019-10-25T00:35:45.760497Z"
    }
   },
   "source": [
    "We can now look at the output files using Python HDF5 libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def hdf5_to_pandas(filename, group_name, timestamp_columns = ['timestamp']):\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        grp = f[group_name]\n",
    "        colnames = [name for name in grp]\n",
    "        columns = {}\n",
    "        for colname in colnames:\n",
    "            if colname in timestamp_columns:\n",
    "                columns[colname] = grp[colname][()].astype('M8[ms]')\n",
    "            else:\n",
    "                columns[colname] = grp[colname][()]\n",
    "\n",
    "    return pd.DataFrame(columns)[colnames]\n",
    "\n",
    "output_filename = output_dir + '/BRKA_2018-01-01_data.hdf5'\n",
    "\n",
    "hdf5_to_pandas(output_filename, 'open_interest')[['timestamp', 'id', 'qty', 'meta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T02:39:28.837703Z",
     "start_time": "2022-08-16T02:39:28.837696Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_to_pandas(output_filename, 'quote_tob')[['timestamp', 'id', 'last_update', 'bid', 'bid_size', 'ask', 'ask_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T02:39:28.838313Z",
     "start_time": "2022-08-16T02:39:28.838309Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_to_pandas(output_filename, 'trade_bars')[['timestamp', 'id', 'o', 'h', 'l', 'c', 'v', 'vwap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T02:39:28.841384Z",
     "start_time": "2022-08-16T02:39:28.841378Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_to_pandas(output_filename, 'other')[['timestamp', 'id', 'meta']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
