# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

__all__ = ['cli_process_zip', 'cli_extend_parquet_with_zip', 'cli_rename_columns']

# Cell
import sys
import argparse
import pathlib

import yaml
import pandas as pd

import dlsproc.extend
import dlsproc.hier
import dlsproc.assemble

# Cell
def cli_process_zip(args: list = None) -> None:

    parser = argparse.ArgumentParser(description='Process zip file')

    parser.add_argument('zip_file', type=argparse.FileType('r'), help='zip file')
    parser.add_argument('output_file', help='Output (parquet) file')

    command_line_arguments = parser.parse_args(args)

    output_file = pathlib.Path(command_line_arguments.output_file)
    assert output_file.suffix == '.parquet', 'a .parquet file was expected'

    data_df, deleted_series = dlsproc.assemble.distilled_data_from_zip(command_line_arguments.zip_file.name)

    res = dlsproc.assemble.merge_deleted(data_df, deleted_series)
    res = dlsproc.assemble.parquet_amenable(res)

    res.to_parquet(output_file)

# Cell
def cli_extend_parquet_with_zip(args: list = None) -> None:

    parser = argparse.ArgumentParser(description='Extend existing parquet file with data from a given zip')

    parser.add_argument('history_file', type=argparse.FileType('r'), help='Parquet file')
    parser.add_argument('zip_file', type=argparse.FileType('r'), help='Zip file')
    parser.add_argument('output_file', help='Output (parquet) file')

    command_line_arguments = parser.parse_args(args)

    history_file = pathlib.Path(command_line_arguments.history_file.name)
    zip_file = pathlib.Path(command_line_arguments.zip_file.name)

    output_file = pathlib.Path(command_line_arguments.output_file)
    assert output_file.suffix == '.parquet', 'a .parquet file was expected'

    dlsproc.extend.parquet_with_zip(history_file, zip_file, output_file)

# Cell
def cli_rename_columns(args: list = None) -> None:

    parser = argparse.ArgumentParser(description='Rename columns')

    parser.add_argument('hierarchical_file', type=argparse.FileType('r'), help='(Hierarchical) Parquet file')
    parser.add_argument('mapping_file', type=argparse.FileType('r'), help='YAML file mapping hierarchical colum names to plain ones')
    parser.add_argument('output_file', help='Output (parquet) file')

    command_line_arguments = parser.parse_args(args)

    hierarchical_file = pathlib.Path(command_line_arguments.hierarchical_file.name)
    assert hierarchical_file.suffix == '.parquet', 'a (hierarchical) .parquet file was expected'

    mapping_file = pathlib.Path(command_line_arguments.mapping_file.name)
    assert (mapping_file.suffix == '.yaml') or (mapping_file.suffix == '.YAML'), 'a YAML file was expected'

    output_file = pathlib.Path(command_line_arguments.output_file)
    assert output_file.suffix == '.parquet', 'a .parquet file was expected'

    with mapping_file.open() as yaml_data:
        data_scheme = yaml.load(yaml_data, Loader=yaml.FullLoader)

    df = pd.read_parquet(hierarchical_file)
    renamed_cols_df = dlsproc.hier.flatten_columns_names(df, data_scheme)

    renamed_cols_df.to_parquet(output_file)