<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20220724</date><key>pmc.key</key><document><id>9242688</id><infon key="license">NO-CC CODE</infon><passage><infon key="article-id_doi">10.1016/j.cmpb.2022.106981</infon><infon key="article-id_pii">S0169-2607(22)00363-7</infon><infon key="article-id_pmc">9242688</infon><infon key="article-id_pmid">35863125</infon><infon key="article-id_publisher-id">106981</infon><infon key="fpage">106981</infon><infon key="kwd">COVID-19 VOC-DL model Variant LSTM Prediction Time series</infon><infon key="license">Since January 2020 Elsevier has created a COVID-19 resource centre with free information in English and Mandarin on the novel coronavirus COVID-19. The COVID-19 resource centre is hosted on Elsevier Connect, the company's public news and information website. Elsevier hereby grants permission to make all its COVID-19-related research that is available on the COVID-19 resource centre - including this research content - immediately available in PubMed Central and other publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.</infon><infon key="lpage">106981</infon><infon key="name_0">surname:Liao;given-names:Zhifang</infon><infon key="name_1">surname:Song;given-names:Yucheng</infon><infon key="name_2">surname:Ren;given-names:Shengbing</infon><infon key="name_3">surname:Song;given-names:Xiaomeng</infon><infon key="name_4">surname:Fan;given-names:Xiaoping</infon><infon key="name_5">surname:Liao;given-names:Zhining</infon><infon key="section_type">TITLE</infon><infon key="title">Keywords</infon><infon key="type">front</infon><infon key="volume">224</infon><infon key="year">2022</infon><offset>0</offset><text>VOC-DL: Deep learning prediction model for COVID-19 based on VOC virus variants</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>80</offset><text>Background and objective</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>105</offset><text>The ever-mutating COVID-19 has infected billions of people worldwide and seriously affected the stability of human society and the world economic development. Therefore, it is essential to make long-term and short-term forecasts for COVID-19. However, the pandemic situation in different countries and regions may be dominated by different virus variants, and the transmission capacity of different virus variants diversifies. Therefore, there is a need to develop a predictive model that can incorporate mutational information to make reasonable predictions about the current pandemic situation.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>702</offset><text>Methods</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>710</offset><text>This paper proposes a deep learning prediction framework, VOC-DL, based on Variants Of Concern (VOC). The framework uses slope feature method to process the time series dataset containing VOC variant information, and uses VOC-LSTM, VOC-GRU and VOC-BILSTM prediction models included in the framework to predict the daily newly confirmed cases.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>1053</offset><text>Results</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>1061</offset><text>We analyzed daily newly confirmed cases in Italy, South Korea, Russia, Japan and India from April 14th, 2021 to July 3rd, 2021. The experimental results show that all VOC-DL models proposed in this paper can accurately predict the pandemic trend in the medium and long term, and VOC-LSTM model has the best prediction performance, with the highest average determination coefficient R2 of 96.83% in five nations’ datasets. The overall prediction has robustness.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>1524</offset><text>Conclusions</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>1536</offset><text>The experimental results show that VOC-LSTM is the best predictor for such a series of data and has higher prediction accuracy in the long run. At the same time, our VOC-DL framework combining VOC variants has reference significance for predicting other variants in the future.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1814</offset><text>Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1827</offset><text>Since the outbreak of COVID-19, the pandemic has spread rapidly in many countries and regions of the world, and the World Health Organization declared COVID-19 a Public Health Emergency of International Concern (PHEIC) on 30th January 2020. According to the research published in the Journal of Virology, COVID-19 has evolved into more than 800 different subtypes and branches since late 2019. In February of 2021, mutated strains of the novel coronavirus were found in Japan and the Philippines. Indian scientists found more than 240 new mutated strains locally, including Delta. On 28th November, 2021, a new virus variant called Omicron was discovered in South Africa. According to a statement issued by the WHO, the variants spread faster and pose a higher risk of reinfection. Therefore, prediction of COVID-19 trends, especially those dominated by different mutant strains, is particularly important. In the future, it can also help medical institutions to build a reasonable and effective medical and health big data platform. There have been numerous studies that have predicted the pandemic trends in different countries and regions, which can be broadly divided into three categories: statistical modeling, mathematical pandemic modeling, and deep learning method.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3102</offset><text>Statistical modeling uses case reports and other data to estimate the significant pandemic parameters, including primary reproductive number (R0), incubation period, sequence interval and reproductive time. Moreover, it then uses mathematical models such as exponential growth to predict pandemic curves. Sanche et al. collected extensive case reports to estimate key epidemiological parameters and prove the need for taking strong control measures as early as possible to stop transmission of the virus. Li et al. analyzed the spread of COVID-19 in Hubei Province of China using Gaussian distribution and predicted the pandemic trend in South Korea, Italy and Iran. The results showed the evolution process of the pandemic and found that implementing control measures can have a positive effect. López and Rodó proposed a modified SEIR partition model. The model takes into account the spread of latent infection and incorporates varying proportions of containment effects. Statistical modeling methods, however, are suitable for rough estimation of outbreaks in their early stages. With the evolving of the pandemic, these pandemic parameters continuously change across countries and regions, which makes the methodology unable to reflect the actual situation of the pandemic.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4385</offset><text>Among mathematical epidemiological models, the most commonly used models are Susceptible, Infected, and Recovered (SIR) and Susceptible, Exposed, Infected, and Recovered (SEIR). The majority of studies examine COVID-19 transmission patterns using the corresponding alterations and adjustments of these two models. Chen et al. proposed a time-related susceptibility-infection-recovery (SIR) model, using machine learning methods to train the time parameters, to predict the number of infections and recovery. Wangping et al. proposed the dynamic extended SIR model of infectious Diseases (eSIR), which added the transmission rate modifier π(t) into the SIR model to estimate the pandemic trends in Italy and Hunan. Liao et al. proposed a SIR prediction model based on time-window, which introduced the time-window mechanism for dynamic data analysis and used machine learning methods to predict the basic reproductive number and exponential growth rate of pandemics. Due to the long duration of COVID-19, changes in parameters of traditional prediction models are related to many factors, and it is also a challenge whether a single model can well adapt to the actual situation. So, in order to effectively predict COVID-19, more advanced methods should be used.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5651</offset><text>With the progress and development of modern artificial intelligence, deep learning technology, as an emerging method, has been widely applied in the analysis and prediction of COVID-19 pandemic. Shastri et al. used stacked LSTMs, bidirectional LSTMs, and convolutional LSTMs to predict confirmed covid-19 cases in the next month. Zeroual et al. used five deep learning methods including RNN, LSTM, BiLSTM, GRU and VAE to predict the number of newly confirmed cases and recovered cases of COVID-19. Arora et al. used LSTM as the prediction model to predict the number of daily and weekly confirmed cases, and the experimental results showed that Bi-LSTM produced very accurate results for short-term (1–3 days) prediction (The error was less than 3%). Wang et al. proposed LSTM model with rolling updating mechanism for long-term prediction and simulated the pandemic trends of Russia, Peru and Iran in the next 150 days. Liao et al. proposed a time-dependent SIRVD prediction model, which combined deep learning technology with mathematical model of infectious diseases. Experimental results showed that this model was improved by 50% in terms of single-day prediction of COVID-19, compared with pure deep learning method. And it can adapt to short term and medium term prediction. Ketu and Mishra used additional convolutional layers in the LSTM layer to construct a CNN-LSTM hybrid deep learning prediction model, through which the COVID-19 pandemic across India was correctly predicted. Alassafi et al. proposed a DL method using RNN and LSTM networks for predicting COVID-19 cases and compared the effects of various activation functions. The number of confirmed cases in Malaysia, Morocco and Saudi Arabia was then expected. Wang et al. proposed a T-SIRGAN network model integrating the advantages of epidemiological theory and deep learning models, which adopted a SIR model to generate simulated data, which was then fed into a Generative Adversarial Network (GAN) as a data-augmented negative example. Then, use the generated synthetic data to predict future trends of COVID-19. Ahuja et al. developed a new deep learning framework to predict and analyze COVID-19 cases in India using CNNs and superimposed dual grid cells. From the research above, deep learning can provide reliable single-day prediction results.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7984</offset><text>RQ1: Does it improve the prediction performance of the model to use slope feature method to process newly confirmed cases as the incremental feature of the training model?</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8156</offset><text>RQ2: Can the performance be improved by adding VOC variant data as model features?</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8239</offset><text>RQ3: Which has a better prediction effect, LSTM, BI-LSTM or GRU? How well does the framework perform in mid-short-term forecasting?</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8371</offset><text>While these studies provided accurate predictions of COVID-19 trends, they did not consider the impact of virus variants on the spread of the pandemic. Under the current situation of constant mutation of virus genes, the pandemic in different countries and regions may be dominated by different virus variants. Therefore, taking virus variants as a feature will be more targeted to adapt to the pandemic fluctuation trend in different regions, so that the trained prediction model can have better prediction performance. As a result, this paper proposes a COVID-19 prediction framework, VOC-DL(based on Variant Of Concerned Deep Learning), to solve this problem. We first obtained the data of daily infection and variant from the public pandemic database, and then preprocessed the data using slope feature method. The fluctuation trend of the data was reflected by their slope. Finally, we used the VOC-DL prediction framework to predict the daily number of newly confirmed cases. We have conducted relevant numerical experiments and mainly focused on solving these three important research questions. </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9475</offset><text>The rest of the paper is organized as follows: In Section 2, we proposed a VOC-DL prediction framework. In Section 3, we carried out numerical experiments and analyzed the experimental results to illustrate the effectiveness of our framework. Then, in Section 4, we had some discussion. The last part is the summary of the paper.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>9808</offset><text>Methodology</text></passage><passage><infon key="file">gr1_lrg.jpg</infon><infon key="id">fig0001</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>9820</offset><text>The overall workflow of the VOC-DL prediction model.</text></passage><passage><infon key="file">gr1_lrg.jpg</infon><infon key="id">fig0001</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>9873</offset><text>Fig 1</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9879</offset><text>VOC-DL prediction framework is divided into three main parts: COVID-19 data collection, data preprocessing and the construction of a VOC-DL prediction framework. The overall workflow of the framework is shown in Fig. 1 .</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10101</offset><text>Step 1: COVID-19 data collection. First, get a COVID-19 dataset, which includes the daily number of newly confirmed cases, cumulative confirmed cases, recovered cases and deaths. Then, the daily new VOC variant data were obtained based on the percentage of VOC variant sequenced samples. Finally, the datasets are combined into the dataset used in this paper.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10461</offset><text>Step 2: Data preprocessing. Firstly, the slope feature method is used to preprocess the fusion dataset obtained in the first step. In order to better represent the epidemic trend, we use the slope information of the number of newly diagnosed cases in the adjacent two days for feature engineering. The data are then converted into the format required by the VOC-DL framework.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10837</offset><text>Step 3: Build the VOC-DL prediction framework. Based on the data obtained in the previous step, a time series vector is constructed as input. Deep learning methods such as LSTM and its variants are used for model training and evaluation to select the optimal model parameters. The VOC-DL framework, using the best model parameters, was then built to predict the number of COVID-19 infections.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11230</offset><text>The VOC-DL aims at assessing changes in the daily number of new infections of a pandemic in order to develop the best models for predicting pandemic trends. In the remainder of this section, we will describe each part in detail.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>11459</offset><text>COVID-19 data collection</text></passage><passage><infon key="file">tbl0001.xml</infon><infon key="id">tbl0001</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>11484</offset><text>Sample data of global confirmed cases from Johns Hopkins University.</text></passage><passage><infon key="file">tbl0001.xml</infon><infon key="id">tbl0001</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot;&gt;Province/State&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Country/Region&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Latitude&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Longitude&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;1/22/20&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;1/23/20&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;...&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;9/29/21&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;9/30/21&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;...&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Beijing&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;China&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;40.1824&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;116.4142&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;14&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;22&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1123&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1124&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Chongqing&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;China&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;30.0572&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;107.874&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;6&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;9&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;603&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;603&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Fujian&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;China&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;26.0789&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;117.9874&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;5&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1282&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1282&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Gansu&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;China&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;35.7518&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;104.2861&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;199&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;199&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>11553</offset><text>Table 1	 	</text></passage><passage><infon key="file">tbl0001.xml</infon><infon key="id">tbl0001</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot;&gt;Province/State&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Country/Region&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Latitude&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Longitude&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;1/22/20&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;1/23/20&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;...&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;9/29/21&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;9/30/21&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;...&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Beijing&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;China&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;40.1824&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;116.4142&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;14&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;22&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1123&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1124&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Chongqing&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;China&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;30.0572&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;107.874&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;6&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;9&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;603&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;603&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Fujian&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;China&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;26.0789&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;117.9874&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;5&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1282&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1282&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Gansu&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;China&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;35.7518&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;104.2861&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;199&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;199&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;...&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>11564</offset><text>Province/State	Country/Region	Latitude	Longitude	1/22/20	1/23/20	...	9/29/21	9/30/21	...	 	Beijing	China	40.1824	116.4142	14	22	...	1123	1124	...	 	Chongqing	China	30.0572	107.874	6	9	...	603	603	...	 	Fujian	China	26.0789	117.9874	1	5	...	1282	1282	...	 	Gansu	China	35.7518	104.2861	0	2	...	199	199	...	 	</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11872</offset><text>Since the outbreak of COVID-19, many institutions have released various public data sources to help researchers conduct up-to-date analyses and forecasts of the outbreak. This paper collects relevant research data from two data sources, and then merges the two datasets to form the dataset used in this paper. The first data source is the time series data collected by the Center of System Science and Engineering (CSSE) at Johns Hopkins University (https://github.com/CSSEGISandData/COVID-19). This dataset widely used by many researchers includes cumulative confirmed cases, cumulative cured cases and cumulative deaths worldwide. The dataset provides variables including country, province, longitude and latitude, as well as the corresponding number of cases to the date. Table 1 shows a partial sample of global confirmed cases.</text></passage><passage><infon key="file">tbl0002.xml</infon><infon key="id">tbl0002</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>12706</offset><text>Sample data of our world in data virus variants.</text></passage><passage><infon key="file">tbl0002.xml</infon><infon key="id">tbl0002</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot;&gt;location&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;date&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;variant&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;num_sequences&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;perc_sequences&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;num_sequences_total&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.160&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.620&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.258&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.221&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.1.302&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.1.277&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.1.519&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.367&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.177&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Beta&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Alpha&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;7&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.68&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Gamma&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Delta&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;8&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.78&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Kappa&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;4&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.39&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Epsilon&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Eta&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Iota&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Lambda&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Mu&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;S:677P.Pelican&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;S:677H.Robin1&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;others&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1007&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;98.15&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;non_who&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1007&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;98.15&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>12755</offset><text>Table 2	 	</text></passage><passage><infon key="file">tbl0002.xml</infon><infon key="id">tbl0002</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot;&gt;location&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;date&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;variant&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;num_sequences&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;perc_sequences&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;num_sequences_total&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.160&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.620&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.258&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.221&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.1.302&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.1.277&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.1.519&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.367&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;B.1.177&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Beta&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Alpha&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;7&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.68&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Gamma&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Delta&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;8&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.78&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Kappa&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;4&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.39&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Epsilon&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Eta&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Iota&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Lambda&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Mu&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;S:677P.Pelican&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;S:677H.Robin1&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;others&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1007&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;98.15&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;India&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2020/12/21&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;non_who&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1007&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;98.15&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1026&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>12766</offset><text>location	date	variant	num_sequences	perc_sequences	num_sequences_total	 	India	2020/12/21	B.1.160	0	0	1026	 	India	2020/12/21	B.1.620	0	0	1026	 	India	2020/12/21	B.1.258	0	0	1026	 	India	2020/12/21	B.1.221	0	0	1026	 	India	2020/12/21	B.1.1.302	0	0	1026	 	India	2020/12/21	B.1.1.277	0	0	1026	 	India	2020/12/21	B.1.1.519	0	0	1026	 	India	2020/12/21	B.1.367	0	0	1026	 	India	2020/12/21	B.1.177	0	0	1026	 	India	2020/12/21	Beta	0	0	1026	 	India	2020/12/21	Alpha	7	0.68	1026	 	India	2020/12/21	Gamma	0	0	1026	 	India	2020/12/21	Delta	8	0.78	1026	 	India	2020/12/21	Kappa	4	0.39	1026	 	India	2020/12/21	Epsilon	0	0	1026	 	India	2020/12/21	Eta	0	0	1026	 	India	2020/12/21	Iota	0	0	1026	 	India	2020/12/21	Lambda	0	0	1026	 	India	2020/12/21	Mu	0	0	1026	 	India	2020/12/21	S:677P.Pelican	0	0	1026	 	India	2020/12/21	S:677H.Robin1	0	0	1026	 	India	2020/12/21	others	1007	98.15	1026	 	India	2020/12/21	non_who	1007	98.15	1026	 	</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13685</offset><text>The second data source is the Our World In Data (https://github.com/owid/covid-19-data) which updates daily the data of confirmed cases, deaths, hospitalization, test, vaccination, variant test and other variables. The data used in this article are the COVID-19 variant data collected by Our World In Data team from official GISAID reports. Table 2 shows some sample data of vaccination. In Table 2, location represents the name of the country (or region within the country) and date is the observation date, and variant is the variant name. The variant num_sequences is the number of sequenced samples of each variant and perc_sequences is the percentage of sequenced samples of each variant, and num_sequences_total is the total number of samples sequenced in the last two weeks. VOC variants (Alpha, Beta, Gamma and Delta) were considered as the main features in this study, and other variants with weak transmission ability were categorized as Others without separate consideration. Since Omicron is in the early stage of the outbreak and data are insufficient, it is not considered as a data feature.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>14793</offset><text>Data preprocessing</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>14812</offset><text>Data conversion</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>14828</offset><text>After obtaining VOC virus variant data, we need to convert the data into the format required by VOC-DL. Since we obtained the percentage of the sequenced samples of each variant in the total number of samples sequenced in the last two weeks, we need to convert the data into the percentage of the sequenced samples of each variant in the total number of daily sequenced samples. We use the method of average arithmetic accumulation to calculate the daily proportion of all variants in two weeks (Construct the arithmetic sequence of the starting and ending variant sequencing ratios within 14 days to form the daily sequencing ratio for 14 days), and the calculation equation is shown as (1). vi(n) represents the proportion of the ith variant sequencing number in the total number of the nth biweekly sequencing samples. pi n(t) represents the change function of the sequencing percentage of the ith variant in the nth biweekly sequencing with time. Since the sequencing percentage of each variant in the nth biweekly sequencing is known, the change function of the sequencing percentage of the ith variant with time can be obtained as pi(t) after the daily sequencing percentage of each variant within the biweekly sequencing is calculated, then the daily newly confirmed cases of various variants can be calculated by Eqs. (2) and (3).  </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16169</offset><text>G(t) is the cumulative number of infections and A(t) is the daily total number of new infections. Bi(t) is the daily number of newly confirmed cases of the ith variant. A(t) has such quantitative relationship as shown in Eq. (4), in which VOC is the category of variants. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>16442</offset><text>Data feature engineering</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16467</offset><text>In order to improve learning efficiency, we carried out feature engineering on the data to facilitate model learning. Recent fluctuations in daily additions often demonstrate recent trends in the data. For example, if daily additions are on the rise, it is likely that the same situation will happen in the near future. Therefore, in order to obtain the recent fluctuations of the data, the slope of the daily newly confirmed cases is also taken as a feature in this paper. , the slope value of the daily additions of variant i at moment h, is defined as Eq. (5). </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17033</offset><text> is the daily increase of variant i at momenth.  is the daily increase of variant i at momenth − 1. The daily number of newly confirmed cases is on the rise when  but shows a downward trend when .</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17234</offset><text>We selected the cumulative number of confirmed cases, the daily number of deaths, the daily number of cured cases and the daily number of newly confirmed VOC variant patients, and the slope of the two adjacent days as inputs for model learning. At the same time, the number of newly confirmed cases of the next day was used as the output rather than the cumulative confirmed cases of the next day. The evaluation and comparison of the loss function were facilitated because the value range of newly confirmed cases was relatively small. Finally, MinMaxScaler was used for normalization to place the input data in the range of [0,1] and ensure that all indicators are in the same order of magnitude, making it easier for comprehensive comparison and evaluation.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>17995</offset><text>VOC-DL prediction framework</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18023</offset><text>Deep learning technology is an effective time series prediction method. We will introduce the deep learning models used in this paper and the VOC-DL prediction framework which is based on slope feature engineering and constructed by using these deep learning models, as well as the evaluation indicators of the models.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>18342</offset><text>Deep learning model</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18362</offset><text>Deep learning (DL) has good performance in time series data analysis and prediction, and can automatically learn the temporal correlation and structure of the data, such as seasonality, periodicity and trend. The framework of this paper mainly uses LSTM deep learning model and its variants. According to the structure, it is divided into Vanilla LSTM, Stacked LSTM, Bidirectional LSTM and GRU, which will all be introduced in detail below.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18803</offset><text>Vanilla LSTM: Vanilla LSTM is the most basic and most widely used LSTM. Compared with the original RNN, LSTM adds one Cell and three Gates. Cell is used to store useful information at the previous moment, and the value of Gate is the degree of retention of the absolute input information. Specifically, the feedforward calculation process of LSTM is shown in Eqs. (6)–(11).      </text></passage><passage><infon key="file">gr2_lrg.jpg</infon><infon key="id">fig0002</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>19185</offset><text>Vanilla LSTM network structure.</text></passage><passage><infon key="file">gr2_lrg.jpg</infon><infon key="id">fig0002</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>19217</offset><text>Fig 2</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19223</offset><text>Wi,Wf,Wo,Wcrepresent the matrix parameters associated with the input and three Gates. b, bf,bo,bcrepresent bias offset parameters associated with the input and three Gates. σrepresents the Sigmoid function. ○ represents the multiplication of two elements in the same position of vectors. Vanilla LSTM's network structure is shown in Fig. 2 .</text></passage><passage><infon key="file">gr3_lrg.jpg</infon><infon key="id">fig0003</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>19569</offset><text>BiDirectional LSTM network structure.</text></passage><passage><infon key="file">gr3_lrg.jpg</infon><infon key="id">fig0003</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>19607</offset><text>Fig 3</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19613</offset><text>BiDirectional LSTM: A standard RNN can only process input in one direction and the future information. BiDirectional LSTM can extract complete time information at time T by considering past and future information, thus improving the performance of the model on sequence problems. The basic structure of bidirectional LSTM is shown in Fig. 3 .</text></passage><passage><infon key="file">gr4_lrg.jpg</infon><infon key="id">fig0004</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>19957</offset><text>Stacked LSTM network structure.</text></passage><passage><infon key="file">gr4_lrg.jpg</infon><infon key="id">fig0004</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>19989</offset><text>Fig 4</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19995</offset><text>Stacked LSTM: Stacked LSTM, also known as Deep LSTM, is an extension of the Vanilla LSTM described above. It is composed of multiple Vanilla LSTM layers, producing a stacked structure, which is shown in Fig. 4 . Each LSTM layer in the middle outputs a sequence vector that is used as input in the next LSTM layer. The stacked LSTM provides output for each timestamp, rather than a single output for all timestamps.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20411</offset><text>GRU: Although LSTM can well alleviate the gradient problem in RNN, the introduction of three additional Gates in LSTM makes the number of parameters in a single LSTM cell four times more than that in a single RNN cell. More parameters lead to more computing resources needed. In order to reduce the computation amount of LSTM while maintaining its excellent performance, Cho et al. proposed a cyclic neural network of Gated Recurrent Unit (GRU). GRU is similar to a type of LSTM with forgetting Gate, but the number of parameters in GRU is less than that in LSTM due to the lack of Output Gate. Feedforward calculation of GRU is shown in Eqs. (12)–(15).    </text></passage><passage><infon key="file">gr5_lrg.jpg</infon><infon key="id">fig0005</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>21072</offset><text>GRU network structure.</text></passage><passage><infon key="file">gr5_lrg.jpg</infon><infon key="id">fig0005</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>21095</offset><text>Fig 5</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21101</offset><text>Wu,Uu,bu,Wr,Ur,br,Wh,Uh,bhrepresent the training parameters associated with the input and 2 Gates. σrepresents the Sigmoid function. ○ represents the multiplication of two elements in the same position of vectors. The structure of the GRU is shown in Fig. 5 .</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>21365</offset><text>VOC-DL prediction framework using slope feature engineering</text></passage><passage><infon key="file">gr6_lrg.jpg</infon><infon key="id">fig0006</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>21425</offset><text>The VOC-DL prediction framework used in the experiment.</text></passage><passage><infon key="file">gr6_lrg.jpg</infon><infon key="id">fig0006</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>21481</offset><text>Fig 6</text></passage><passage><infon key="file">gr7_lrg.jpg</infon><infon key="id">fig0007</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>21487</offset><text>Single-day forecasts in India using BiDirectional LSTM with slope features.</text></passage><passage><infon key="file">gr7_lrg.jpg</infon><infon key="id">fig0007</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>21563</offset><text>Fig 7</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21569</offset><text>COVID-19 has many potential factors due to the fact that there are incubation periods and asymptomatic carriers in this disease. However, many features are required to discover these potential effects, and simply feeding sequence data into an LSTM and its variants may not yield desirable results. Therefore, we first extract data features through a fully connected layer and take them as the input of LSTM and its variants, so as to obtain multiple time series outputs, and we finally input these outputs into the fully connected layer to combine the features and then output. The framework structure is shown in Fig. 6 .</text></passage><passage><infon key="file">tbl0011.xml</infon><infon key="id">tbl0011</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>22193</offset><text>VOC-DL prediction model.</text></passage><passage><infon key="file">tbl0011.xml</infon><infon key="id">tbl0011</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Input:&lt;/bold&gt; {&lt;italic&gt;T&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;R&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;D&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;VOC&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), 0 ≤ &lt;italic&gt;t&lt;/italic&gt; ≤ &lt;italic&gt;T&lt;/italic&gt; − 1}, w: the time window size, n: the feature number, d: the prediction days&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1: Data preprocessing&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2: Get the input of VOC-DL: {&lt;italic&gt;A&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;B&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;I&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;R&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;D&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), 0 ≤ &lt;italic&gt;t&lt;/italic&gt; ≤ &lt;italic&gt;T&lt;/italic&gt; − 1} using Eqs. (1)–(3)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3: while 0 ≤ &lt;italic&gt;t&lt;/italic&gt; ≤ &lt;italic&gt;T&lt;/italic&gt; − 1 do:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4:   calculate gradient {&lt;italic&gt;S&lt;sub&gt;i&lt;/sub&gt;&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;),&lt;italic&gt;i&lt;/italic&gt; ∈ &lt;italic&gt;VOC&lt;/italic&gt;} using Eq. (6)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5: end while&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6: Define &lt;italic&gt;X&lt;/italic&gt; as the deep learning model input, |&lt;italic&gt;X&lt;/italic&gt;| = (&lt;italic&gt;T&lt;/italic&gt; − &lt;italic&gt;w&lt;/italic&gt; − &lt;italic&gt;d&lt;/italic&gt;) × &lt;italic&gt;w&lt;/italic&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7: while 0 ≤ &lt;italic&gt;t&lt;/italic&gt; ≤ &lt;italic&gt;T&lt;/italic&gt; − &lt;italic&gt;w&lt;/italic&gt; − &lt;italic&gt;d&lt;/italic&gt; do:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;8:   Define &lt;italic&gt;S&lt;sub&gt;i&lt;/sub&gt;&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;) as the feature vector&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;9:   &lt;inline-formula&gt;&lt;mml:math id=&quot;M21&quot; altimg=&quot;si1.svg&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;S&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;mml:mo linebreak=&quot;goodbreak&quot;&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;[&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;S&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;S&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mo&gt;⋯&lt;/mml:mo&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;S&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;/mml:msubsup&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;∈&lt;/mml:mo&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;]&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;10:   Append &lt;italic&gt;X&lt;/italic&gt; with &lt;italic&gt;S&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;11: end while&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;12: MinMaxScaler&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;13: Define &lt;italic&gt;Y&lt;/italic&gt; as the object value, |&lt;italic&gt;Y&lt;/italic&gt;| = (&lt;italic&gt;T&lt;/italic&gt; − &lt;italic&gt;w&lt;/italic&gt; − &lt;italic&gt;d&lt;/italic&gt;) × &lt;italic&gt;d&lt;/italic&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;14: Split the train set and test set by &lt;italic&gt;X, Y&lt;/italic&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;15: Train and evaluate the model using deep learning methods&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;16: Output: the predicted values &lt;inline-formula&gt;&lt;mml:math id=&quot;M22&quot; altimg=&quot;si2.svg&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>22218</offset><text>Table 10	 	</text></passage><passage><infon key="file">tbl0011.xml</infon><infon key="id">tbl0011</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Input:&lt;/bold&gt; {&lt;italic&gt;T&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;R&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;D&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;VOC&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), 0 ≤ &lt;italic&gt;t&lt;/italic&gt; ≤ &lt;italic&gt;T&lt;/italic&gt; − 1}, w: the time window size, n: the feature number, d: the prediction days&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1: Data preprocessing&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2: Get the input of VOC-DL: {&lt;italic&gt;A&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;B&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;I&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;R&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), &lt;italic&gt;D&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;), 0 ≤ &lt;italic&gt;t&lt;/italic&gt; ≤ &lt;italic&gt;T&lt;/italic&gt; − 1} using Eqs. (1)–(3)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3: while 0 ≤ &lt;italic&gt;t&lt;/italic&gt; ≤ &lt;italic&gt;T&lt;/italic&gt; − 1 do:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4:   calculate gradient {&lt;italic&gt;S&lt;sub&gt;i&lt;/sub&gt;&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;),&lt;italic&gt;i&lt;/italic&gt; ∈ &lt;italic&gt;VOC&lt;/italic&gt;} using Eq. (6)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5: end while&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6: Define &lt;italic&gt;X&lt;/italic&gt; as the deep learning model input, |&lt;italic&gt;X&lt;/italic&gt;| = (&lt;italic&gt;T&lt;/italic&gt; − &lt;italic&gt;w&lt;/italic&gt; − &lt;italic&gt;d&lt;/italic&gt;) × &lt;italic&gt;w&lt;/italic&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7: while 0 ≤ &lt;italic&gt;t&lt;/italic&gt; ≤ &lt;italic&gt;T&lt;/italic&gt; − &lt;italic&gt;w&lt;/italic&gt; − &lt;italic&gt;d&lt;/italic&gt; do:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;8:   Define &lt;italic&gt;S&lt;sub&gt;i&lt;/sub&gt;&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;) as the feature vector&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;9:   &lt;inline-formula&gt;&lt;mml:math id=&quot;M21&quot; altimg=&quot;si1.svg&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;S&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;mml:mo linebreak=&quot;goodbreak&quot;&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;[&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;S&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;S&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mo&gt;⋯&lt;/mml:mo&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;S&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;/mml:msubsup&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;∈&lt;/mml:mo&gt;&lt;mml:mi&gt;V&lt;/mml:mi&gt;&lt;mml:mi&gt;O&lt;/mml:mi&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;]&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;10:   Append &lt;italic&gt;X&lt;/italic&gt; with &lt;italic&gt;S&lt;/italic&gt;(&lt;italic&gt;t&lt;/italic&gt;)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;11: end while&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;12: MinMaxScaler&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;13: Define &lt;italic&gt;Y&lt;/italic&gt; as the object value, |&lt;italic&gt;Y&lt;/italic&gt;| = (&lt;italic&gt;T&lt;/italic&gt; − &lt;italic&gt;w&lt;/italic&gt; − &lt;italic&gt;d&lt;/italic&gt;) × &lt;italic&gt;d&lt;/italic&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;14: Split the train set and test set by &lt;italic&gt;X, Y&lt;/italic&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;15: Train and evaluate the model using deep learning methods&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;16: Output: the predicted values &lt;inline-formula&gt;&lt;mml:math id=&quot;M22&quot; altimg=&quot;si2.svg&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;mml:mo&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>22230</offset><text>Input: {T(t), R(t), D(t), VOC(t), 0 ≤ t ≤ T − 1}, w: the time window size, n: the feature number, d: the prediction days	 	1: Data preprocessing	 	2: Get the input of VOC-DL: {A(t), B(t), I(t), R(t), D(t), 0 ≤ t ≤ T − 1} using Eqs. (1)–(3)	 	3: while 0 ≤ t ≤ T − 1 do:	 	4:   calculate gradient {Si(t),i ∈ VOC} using Eq. (6)	 	5: end while	 	6: Define X as the deep learning model input, |X| = (T − w − d) × w	 	7: while 0 ≤ t ≤ T − w − d do:	 	8:   Define Si(t) as the feature vector	 	9:   	 	10:   Append X with S(t)	 	11: end while	 	12: MinMaxScaler	 	13: Define Y as the object value, |Y| = (T − w − d) × d	 	14: Split the train set and test set by X, Y	 	15: Train and evaluate the model using deep learning methods	 	16: Output: the predicted values 	 	</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>23074</offset><text>In the time range of length T, let the output dimension of the model be d and the time window size be w. Formula (6) was first used to calculate the slope information that could reflect the volatility of data, and then input data with the size of (T − w − d) × w were constructed. Finally, the number of new infections in the future was predicted through training and evaluation of the model. The prediction Algorithm is shown in Algorithm 1 .</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>23530</offset><text>Model evaluation indicators</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>23558</offset><text>The accuracy of the model can be evaluated by comparing actual and predicted values. This study used four evaluation indicators for effective comparison: Mean Absolute Error (MAE), Root Mean Square Error (RMSE), coefficient of determination (R2), and Mean Absolute Percentage Error (MAPE). The calculation method is shown in Eqs. (16)–(19).    </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>23905</offset><text>Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>23913</offset><text>Parameter Settings</text></passage><passage><infon key="file">tbl0003.xml</infon><infon key="id">tbl0003</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>23932</offset><text>Hyperparameters for training.</text></passage><passage><infon key="file">tbl0003.xml</infon><infon key="id">tbl0003</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot;&gt;Hyperparameter&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Possible values&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Epochs&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;{300}&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Batch Size&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;{32}&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Learning rate&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;{0.1,0.01,0.001,0.0001,0.00001}&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Optimizer&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;{Adam}&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>23962</offset><text>Table 3	 	</text></passage><passage><infon key="file">tbl0003.xml</infon><infon key="id">tbl0003</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot;&gt;Hyperparameter&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Possible values&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Epochs&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;{300}&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Batch Size&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;{32}&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Learning rate&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;{0.1,0.01,0.001,0.0001,0.00001}&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Optimizer&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;{Adam}&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>23973</offset><text>Hyperparameter	Possible values	 	Epochs	{300}	 	Batch Size	{32}	 	Learning rate	{0.1,0.01,0.001,0.0001,0.00001}	 	Optimizer	{Adam}	 	</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>24107</offset><text>The simulations and experiments were conducted using open-source platforms (NumPy, Pandas and TensorFlow) on NVIDIA GTX 1070 and coded by Python Keras. The main hyperparameters (Epoch, batchsize, learning rate) used in the experiments were selected using an exhaustive search method. where the learning rate is updated using an equally spaced rate decreasing method. The optimal hyperparameter combinations we screened out are shown in Table 3 .</text></passage><passage><infon key="file">tbl0004.xml</infon><infon key="id">tbl0004</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>24554</offset><text>Number of layers and units and total number of parameters of each deep learning method.</text></passage><passage><infon key="file">tbl0004.xml</infon><infon key="id">tbl0004</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;top&quot;&gt;Method&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Parameter&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Values&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Vanilla LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Number of layers&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Number of Units&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;32&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Total Params&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;8529&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;BiDirectional LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Number of layers&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Number of Units&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;32&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Total Params&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;16,849&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Stacked LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Number of layers&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Number of Units&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;32&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Total Params&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;13,089&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Number of layers&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Number of Units&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;32&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Total Params&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;6961&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>24642</offset><text>Table 4	 	</text></passage><passage><infon key="file">tbl0004.xml</infon><infon key="id">tbl0004</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;top&quot;&gt;Method&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Parameter&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Values&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Vanilla LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Number of layers&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Number of Units&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;32&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Total Params&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;8529&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;BiDirectional LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Number of layers&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Number of Units&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;32&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Total Params&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;16,849&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Stacked LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Number of layers&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Number of Units&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;32&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Total Params&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;13,089&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Number of layers&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Number of Units&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;32&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Total Params&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;6961&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>24653</offset><text>Method	Parameter	Values	 	Vanilla LSTM	Number of layers	4	 	Number of Units	32	 	Total Params	8529	 	BiDirectional LSTM	Number of layers	4	 	Number of Units	32	 	Total Params	16,849	 	Stacked LSTM	Number of layers	3	 	Number of Units	32	 	Total Params	13,089	 	GRU	Number of layers	4	 	Number of Units	32	 	Total Params	6961	 	</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>24981</offset><text>In this article, Vanilla LSTM, Stacked LSTM, Bidirectional LSTM and GRU were all implemented using the Keras package and MAE was used as the loss function. Table 4 shows the number of layers and units and the total number of parameters for each method.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>25235</offset><text>The data set used in the experiment was historical pandemic data in India from May 11th, 2020 to September 6th, 2021. In order to find more latent cases, we set the time series window size to 3 days. The data are divided into training sets and test sets to train and test our prediction model.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>25529</offset><text>Experiment and result analysis</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>25560</offset><text>RQ1 Does it improve the prediction performance of the model to use slope feature method to treat newly confirmed cases and take it as the incremental feature of training model?</text></passage><passage><infon key="file">tbl0005.xml</infon><infon key="id">tbl0005</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>25737</offset><text>Single-day prediction results of slope feature comparison experiment in the test set.</text></passage><passage><infon key="file">tbl0005.xml</infon><infon key="id">tbl0005</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;top&quot;&gt;Method&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Evaluation indicator&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Without slope feature&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;With slope feature&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Change&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Bi-LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.237&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.102&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.135&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;89.88%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;96.10%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑6.22%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.072&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.066&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.006&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;91.89%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;92.48%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑0.59%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Vanilla LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.133&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.081&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.051&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;93.56%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.22%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑0.66%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>25823</offset><text>Table 5	 	</text></passage><passage><infon key="file">tbl0005.xml</infon><infon key="id">tbl0005</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;top&quot;&gt;Method&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Evaluation indicator&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Without slope feature&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;With slope feature&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Change&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Bi-LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.237&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.102&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.135&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;89.88%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;96.10%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑6.22%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.072&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.066&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.006&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;91.89%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;92.48%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑0.59%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Vanilla LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.133&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.081&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.051&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;93.56%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.22%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑0.66%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>25834</offset><text>Method	Evaluation indicator	Without slope feature	With slope feature	Change	 	Bi-LSTM	MAPE	1.237	1.102	↓0.135	 	R2	89.88%	96.10%	↑6.22%	 	GRU	MAPE	1.072	1.066	↓0.006	 	R2	91.89%	92.48%	↑0.59%	 	Vanilla LSTM	MAPE	1.133	1.081	↓0.051	 	R2	93.56%	94.22%	↑0.66%	 	</text></passage><passage><infon key="file">tbl0005.xml</infon><infon key="id">tbl0005</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>26106</offset><text>As shown in Table 5, Vanilla LSTM, BiDirectional LSTM and GRU with slope features were more substantial than the models without slope features based on each evaluation indicator in a single day forecast. MAPE decreased, and R2 increased to certain degrees. The BiDirectional LSTM with the slope feature performed best, with a 1.102 MAPE and a 96.0% R2 improved by 6.22%. So, we can verify that the slope feature method is effective and improves the model's performance. Fig. 7 shows the difference between the number of infections predicted by the best-performing BiDirectional LSTM model and the number of infections.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>26727</offset><text>Vanilla LSTM, BiDirectional LSTM and GRU were trained with the data, whether with or without slope feature processing, to verify the effectiveness of the proposed slope feature method in improving model prediction accuracy. Table 5 shows the comparison of three prediction models (Vanilla LSTM, BiDirectional LSTM and GRU) in a single day. The test dataset is the data in India from April 14th, 2021 to July 3rd, 2021.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>27147</offset><text>RQ2 Can the performance be improved by adding VOC variant data as model features</text></passage><passage><infon key="file">gr8_lrg.jpg</infon><infon key="id">fig0008</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>27228</offset><text>Data distribution of the VOC-DL model (a) Daily number of newly confirmed cases (b) Cumulative number of confirmed cases (c) Cumulative number of deaths (d) Cumulative number of cured cases.</text></passage><passage><infon key="file">gr8_lrg.jpg</infon><infon key="id">fig0008</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>27419</offset><text>Fig 8</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27425</offset><text>As shown in Fig. 8 , the primary infection data in the Indian data set include daily newly confirmed cases, cumulative confirmed cases, cumulative deaths and cumulative cured cases. We applied this data set to our VOC-DL framework to estimate the daily number of newly confirmed cases. It can be observed from Fig. 8(a) that the first round of newly confirmed cases peaked in India on day 129. The second round of new cases peaked on day 369.</text></passage><passage><infon key="file">gr9_lrg.jpg</infon><infon key="id">fig0009</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>27870</offset><text>Daily newly confirmed cases of VOC variants in India.</text></passage><passage><infon key="file">gr9_lrg.jpg</infon><infon key="id">fig0009</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>27924</offset><text>Fig 9</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27930</offset><text>We then visualized the daily number of newly confirmed cases of VOC variants in India (Fig. 9 ). It was found that non-VOC variants dominated the pandemic trend in the early stages of the pandemic, and the newly confirmed cases peaked 125 days later. The second wave was dominated by Alpha and non-VOC variants, with new cases peaking on day 341. The third round was entirely delta-dominated and was rapid, with a sharp increase in the number of confirmed cases, peaking on day 375. Compared with Fig. 8(a), it is found that the data without breaking down the daily newly confirmed cases by variant can only reflect the peak of the two pandemics. However, by dividing the daily number of newly confirmed cases according to variant data, the pandemic peak with low outbreak severity can be discovered, which indicates that VOC variant data can better reflect the fluctuating trend of the pandemic.</text></passage><passage><infon key="file">gr10_lrg.jpg</infon><infon key="id">fig0010</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>28829</offset><text>(a) Daily newly confirmed cases of VOC in Italy (b) Daily newly confirmed cases of VOC in Japan (c) Daily newly confirmed cases of VOC in South Korea (d) Daily newly confirmed cases of VOC in Russia.</text></passage><passage><infon key="file">gr10_lrg.jpg</infon><infon key="id">fig0010</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>29029</offset><text>Fig 10</text></passage><passage><infon key="file">gr11_lrg.jpg</infon><infon key="id">fig0011</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>29036</offset><text>Single-day prediction in India using BiDirectional LSTM with VOC variant features.</text></passage><passage><infon key="file">gr11_lrg.jpg</infon><infon key="id">fig0011</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>29119</offset><text>Fig 11</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>29126</offset><text>We also analyzed a daily number of newly confirmed cases of VOC variants in Italy, Japan, South Korea and Russia. Fig. 10 (a) shows that there were three separate outbreaks in Italy, dominated by non-VOC, Alpha and Delta strains, respectively. Fig. 10(b) shows that Japan also saw three rounds of outbreaks, dominated by non-VOC, Alpha and Delta strains, respectively. Fig. 10(c) shows two rounds of outbreaks in South Korea, dominated by non-VOC and Delta strains. Fig. 10(d) shows two outbreaks in Russia, dominated by non-VOC and Delta strains.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>29678</offset><text>As shown in Fig. 10, the time and degree of the outbreak of all VOC variants are also different in various countries due to the differences in the emergence of variants and the degree of governmental blockade control. However, they can reflect the peaks of outbreaks and pandemic trends in different countries to certain degrees. Therefore, through the visualization of data, it can be seen that the use of VOC variants to divide the daily number of newly confirmed cases can better measure the change in pandemic development, which is the basis for future training of the VOC-DL framework with VOC variants taken as the feature.</text></passage><passage><infon key="file">tbl0006.xml</infon><infon key="id">tbl0006</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>30309</offset><text>Single-day prediction results of VOC data features comparison experiment in the test set.</text></passage><passage><infon key="file">tbl0006.xml</infon><infon key="id">tbl0006</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;top&quot;&gt;Method&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Evaluation indicator&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;VOC—Values&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;NoVOC-Values&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Variation&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Bi-LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0202&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0426&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0225&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0104&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0347&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0242&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;97.25%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;89.88%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑7.37%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0003&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.2367&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.2364&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0202&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0340&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0138&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0112&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0237&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0125&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;97.24%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;93.56%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑3.68%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0144&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.1326&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.1182&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0230&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0382&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0152&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0125&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0228&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0102&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;96.43%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;91.89%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑4.54%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0179&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0718&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0540&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>30399</offset><text>Table 6	 	</text></passage><passage><infon key="file">tbl0006.xml</infon><infon key="id">tbl0006</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;top&quot;&gt;Method&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Evaluation indicator&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;VOC—Values&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;NoVOC-Values&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Variation&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Bi-LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0202&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0426&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0225&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0104&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0347&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0242&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;97.25%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;89.88%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑7.37%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0003&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.2367&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.2364&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0202&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0340&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0138&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0112&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0237&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0125&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;97.24%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;93.56%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑3.68%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0144&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.1326&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.1182&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0230&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0382&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0152&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0125&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0228&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0102&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;96.43%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;91.89%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↑4.54%&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0179&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0718&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;↓0.0540&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>30410</offset><text>Method	Evaluation indicator	VOC—Values	NoVOC-Values	Variation	 	Bi-LSTM	RMSE	0.0202	0.0426	↓0.0225	 	MAE	0.0104	0.0347	↓0.0242	 	R2	97.25%	89.88%	↑7.37%	 	MAPE	1.0003	1.2367	↓0.2364	 	LSTM	RMSE	0.0202	0.0340	↓0.0138	 	MAE	0.0112	0.0237	↓0.0125	 	R2	97.24%	93.56%	↑3.68%	 	MAPE	1.0144	1.1326	↓0.1182	 	GRU	RMSE	0.0230	0.0382	↓0.0152	 	MAE	0.0125	0.0228	↓0.0102	 	R2	96.43%	91.89%	↑4.54%	 	MAPE	1.0179	1.0718	↓0.0540	 	</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>30854</offset><text>In order to further verify the validity of VOC variant data features in terms of improving the accuracy of model prediction, Vanilla LSTM, BiDirectional LSTM and GRU were trained using slope feature processing with data of both VOC and non-VOC variants, and a comparison among them was also conducted. Table 6 compares three prediction models of Vanilla LSTM, BiDirectional LSTM and GRU in a single day.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>31259</offset><text>As shown in Table 6, Vanilla LSTM, BiDirectional LSTM and GRU models with VOC data features all improved to certain degrees based on each evaluation indicator in a single-day forecast. The BiDirectional LSTM with VOC variant features performed best. RMSE was 0.0202, MAE was 0.0104, R2 was 97.25%(Compared with the same model without adding VOC features, it has increased by 7.37%), and MAPE was 1.003. And the Bi-LSTM model with increased VOC has a 0.82% increase in R2 score compared to the poorer GRU model. So we can prove that the VOC variant feature method is effective and can improve the model's performance.</text></passage><passage><infon key="file">tbl0007.xml</infon><infon key="id">tbl0007</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>31877</offset><text>Single-day prediction results of the test set.</text></passage><passage><infon key="file">tbl0007.xml</infon><infon key="id">tbl0007</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot;&gt;Model&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;RMSE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;R2&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAPE&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Vanilla_LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0313&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0210&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.55%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.1300&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Stacked_LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0384&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0226&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;91.80%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0943&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Compare_GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0272&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0184&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;95.88%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0675&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;VOC-BiLSTM&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0202&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0104&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;97.25%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.0003&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;VOC-LSTM&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0202&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0112&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;97.24%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.0144&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;VOC-GRU&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0230&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0125&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;96.43%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.0179&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>31924</offset><text>Table 7	 	</text></passage><passage><infon key="file">tbl0007.xml</infon><infon key="id">tbl0007</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot;&gt;Model&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;RMSE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;R2&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAPE&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Vanilla_LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0313&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0210&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.55%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.1300&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Stacked_LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0384&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0226&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;91.80%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0943&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Compare_GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0272&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0184&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;95.88%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0675&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;VOC-BiLSTM&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0202&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0104&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;97.25%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.0003&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;VOC-LSTM&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0202&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0112&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;97.24%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.0144&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;VOC-GRU&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0230&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0125&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;96.43%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.0179&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>31935</offset><text>Model	RMSE	MAE	R2	MAPE	 	Vanilla_LSTM	0.0313	0.0210	94.55%	1.1300	 	Stacked_LSTM	0.0384	0.0226	91.80%	1.0943	 	Compare_GRU	0.0272	0.0184	95.88%	1.0675	 	VOC-BiLSTM	0.0202	0.0104	97.25%	1.0003	 	VOC-LSTM	0.0202	0.0112	97.24%	1.0144	 	VOC-GRU	0.0230	0.0125	96.43%	1.0179	 	</text></passage><passage><infon key="file">tbl0007.xml</infon><infon key="id">tbl0007</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>32207</offset><text>It can be seen from Table 7 that the performance of the VOC-DL framework with slope feature is superior to all the existing deep learning methods based on each evaluation indicator in the single-day prediction. Among them, the best performing BiDirectional LSTM model is compared to other researchers' methods. Its best results were improved by 5.45%. Fig. 11 shows the difference between the predicted number of infections and the actual number of infections by the best performing BiDirectional LSTM model.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>32718</offset><text>At the same time, to prove whether VOC-DL improves performance compared with the existing methods, we compared it with the prediction methods using deep learning in existing studies. Among them, Stacked LSTM used the methods of Arora et al. and GRU and Vanilla LSTM used the methods of Nabi et al.. Table 7 shows the comparison between prediction models (VOC-LSTM, VOC-BILSTM and VOC-GRU, added with VOC variant training) and existing methods in single-day predictions.</text></passage><passage><infon key="file">gr12_lrg.jpg</infon><infon key="id">fig0012</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>33191</offset><text>Single-day forecast results in multiple countries: (a) Italian forecast results. (b) Japanese forecast results. (c) Korean forecast results. (d) Russian forecast results.</text></passage><passage><infon key="file">gr12_lrg.jpg</infon><infon key="id">fig0012</infon><infon key="section_type">FIG</infon><infon key="type">fig</infon><offset>33362</offset><text>Fig 12</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>33369</offset><text>Then we apply our framework to the test sets of Italy, Japan, South Korea, and Russia, and the experimental results are shown in Fig. 12 . The experimental results show that our framework can accurately predict the epidemic trend of these countries and has good generality.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>33644</offset><text>RQ3 Which has a better prediction effect, LSTM, Bi-LSTM or GRU? How well does the framework perform in medium-short-term prediction?</text></passage><passage><infon key="file">tbl0008.xml</infon><infon key="id">tbl0008</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>33777</offset><text>Performance of VOC-DL on data sets of Italy, South Korea, Russia and Japan.</text></passage><passage><infon key="file">tbl0008.xml</infon><infon key="id">tbl0008</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;top&quot;&gt;Method&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Country&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;RMSE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;R2&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAPE&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;5&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;VOC-BiLSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Italy&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0135&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0094&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.25%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.2379&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Japan&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0623&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0250&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;95.65%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2.1407&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;South Korea&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0670&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0398&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;92.90%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.7482&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Russia&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0291&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0211&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;98.90%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0726&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;average&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0430&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0238&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;95.43%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.2998&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;5&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;VOC-LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Japan&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0132&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0089&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.54%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.2358&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;South Korea&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0437&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0207&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;97.86%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2.1403&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Russia&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0532&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0331&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;95.51%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.7333&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Japan&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0270&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0210&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;99.01%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0801&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;average&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0343&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0209&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;96.73%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.2974&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;5&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;VOC-GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Japan&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0132&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0087&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.49%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.2621&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;South Korea&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0438&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0236&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;97.85%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2.1935&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Russia&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0610&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0378&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.09%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.7572&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Japan&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0287&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0210&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;98.88%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0717&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;average&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0367&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0228&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;96.33%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.3211&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>33853</offset><text>Table 8	 	</text></passage><passage><infon key="file">tbl0008.xml</infon><infon key="id">tbl0008</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;top&quot;&gt;Method&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Country&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;RMSE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;R2&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAPE&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;5&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;VOC-BiLSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Italy&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0135&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0094&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.25%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.2379&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Japan&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0623&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0250&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;95.65%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2.1407&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;South Korea&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0670&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0398&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;92.90%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.7482&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Russia&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0291&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0211&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;98.90%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0726&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;average&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0430&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0238&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;95.43%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.2998&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;5&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;VOC-LSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Japan&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0132&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0089&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.54%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.2358&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;South Korea&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0437&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0207&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;97.86%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2.1403&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Russia&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0532&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0331&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;95.51%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.7333&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Japan&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0270&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0210&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;99.01%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0801&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;average&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0343&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0209&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;96.73%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.2974&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;5&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;VOC-GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Japan&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0132&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0087&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.49%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.2621&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;South Korea&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0438&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0236&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;97.85%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;2.1935&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Russia&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0610&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0378&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;94.09%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.7572&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Japan&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0287&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0210&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;98.88%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.0717&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;average&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0367&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0228&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;96.33%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.3211&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>33864</offset><text>Method	Country	RMSE	MAE	R2	MAPE	 	VOC-BiLSTM	Italy	0.0135	0.0094	94.25%	1.2379	 	Japan	0.0623	0.0250	95.65%	2.1407	 	South Korea	0.0670	0.0398	92.90%	0.7482	 	Russia	0.0291	0.0211	98.90%	1.0726	 	average	0.0430	0.0238	95.43%	1.2998	 	VOC-LSTM	Japan	0.0132	0.0089	94.54%	1.2358	 	South Korea	0.0437	0.0207	97.86%	2.1403	 	Russia	0.0532	0.0331	95.51%	0.7333	 	Japan	0.0270	0.0210	99.01%	1.0801	 	average	0.0343	0.0209	96.73%	1.2974	 	VOC-GRU	Japan	0.0132	0.0087	94.49%	1.2621	 	South Korea	0.0438	0.0236	97.85%	2.1935	 	Russia	0.0610	0.0378	94.09%	0.7572	 	Japan	0.0287	0.0210	98.88%	1.0717	 	average	0.0367	0.0228	96.33%	1.3211	 	</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>34494</offset><text>To prove the universality of our method and select models that perform better, we used data from Italy, South Korea, Russia and Japan as validation. The data for COVID-19 in all four countries are the same, from April 14th, 2021 to July 3rd, 2021. VOC-LSTM, VOC-BILSTM and VOC-GRU were trained by increasing VOC variant data combined with slope feature method. The predicted results of the three VOC-DL models for these four countries are shown in Table 8 .</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>34953</offset><text>It can be seen from Table 8 that values of the average MAPE of the three VOC-DL models in the data sets of the four countries are all within 1.5%. The average RMSE of VOC-LSTM in other countries’ datasets was 0.0343 and the average MAE was 0.0209 and R2 was 96.73%. The average RMSE of VOC-GRU in other countries’ datasets was 0.0367 and the average MAE was 0.0228 and R2 was 96.33%. The average RMSE of VOC-BiLSTM in other countries’ datasets was 0.043 and the average MAE was 0.0238 and R2 was 95.43%. This indicates that the three VOC-DL models have strong universality and can be used to conduct COVID-19 predictions in other countries and regions.</text></passage><passage><infon key="file">tbl0009.xml</infon><infon key="id">tbl0009</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>35613</offset><text>Performance comparison of the three VOC-DL models in the datasets of Italy, Korea, Russia and Japan.</text></passage><passage><infon key="file">tbl0009.xml</infon><infon key="id">tbl0009</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot;&gt;Method&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;RMSE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;R2&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAPE&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;VOC-GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0367&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0228&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;96.33%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.3211&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;VOC-BiLSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0430&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0238&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;95.43%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.2998&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;VOC-LSTM&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0343&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0209&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;96.73%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.2974&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>35714</offset><text>Table 9	 	</text></passage><passage><infon key="file">tbl0009.xml</infon><infon key="id">tbl0009</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot;&gt;Method&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;RMSE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAE&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;R2&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;MAPE&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;VOC-GRU&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0367&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0228&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;96.33%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.3211&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;VOC-BiLSTM&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0430&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0238&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;95.43%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1.2998&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;VOC-LSTM&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0343&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0209&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;96.73%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;1.2974&lt;/bold&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>35725</offset><text>Method	RMSE	MAE	R2	MAPE	 	VOC-GRU	0.0367	0.0228	96.33%	1.3211	 	VOC-BiLSTM	0.0430	0.0238	95.43%	1.2998	 	VOC-LSTM	0.0343	0.0209	96.73%	1.2974	 	</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>35870</offset><text>To demonstrate which is the better predictor among LSTM, Bi-LSTM and GRU, we compared the performance of three VOC-DL models in four countries’ datasets. Table 9 shows the average of each evaluation indicator for VOC-LSTM, VOC-BILSTM and VOC-GRU based on a single day forecast in four countries. As Table 9 illustrates, VOC-LSTM performed best in datasets from other countries.</text></passage><passage><infon key="file">tbl0010.xml</infon><infon key="id">tbl0010</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>36252</offset><text>Effect of VOC-LSTM model in long-term and short-term predictions.</text></passage><passage><infon key="file">tbl0010.xml</infon><infon key="id">tbl0010</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;top&quot;/&gt;&lt;th valign=&quot;top&quot;/&gt;&lt;th valign=&quot;top&quot;&gt;VOC-LSTM&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Vanilla_LSTM&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Stacked_LSTM&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Compare_GRU&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;3-day&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0154&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1069&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1075&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1117&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0084&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0650&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0682&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0647&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;99.65%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;87.47%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;87.32%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;86.31%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.2255&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3743&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4046&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3461&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;7-day&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0182&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1019&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1068&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1937&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0100&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0649&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0600&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0986&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;99.41%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;88.33%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;87.13%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;58.78%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.2371&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3834&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3339&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4329&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;14-day&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0221&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1903&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1859&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1081&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0135&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0988&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0996&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0556&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;98.81%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;56.49%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;58.17%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;85.11%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.2807&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4599&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4320&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3271&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;21-day&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0223&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1233&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1218&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1340&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0136&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0708&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0651&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0793&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;98.46%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;77.16%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;78.25%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;72.80%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.2892&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3877&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4150&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4264&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;28-day&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0221&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1266&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1535&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1374&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0133&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0706&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0857&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0751&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;97.76%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;69.62%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;55.58%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;63.62%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.3095&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4175&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4874&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4150&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>36318</offset><text>Table 10	 	</text></passage><passage><infon key="file">tbl0010.xml</infon><infon key="id">tbl0010</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;top&quot;/&gt;&lt;th valign=&quot;top&quot;/&gt;&lt;th valign=&quot;top&quot;&gt;VOC-LSTM&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Vanilla_LSTM&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Stacked_LSTM&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;Compare_GRU&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;3-day&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0154&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1069&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1075&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1117&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0084&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0650&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0682&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0647&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;99.65%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;87.47%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;87.32%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;86.31%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.2255&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3743&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4046&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3461&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;7-day&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0182&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1019&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1068&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1937&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0100&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0649&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0600&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0986&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;99.41%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;88.33%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;87.13%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;58.78%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.2371&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3834&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3339&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4329&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;14-day&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0221&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1903&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1859&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1081&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0135&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0988&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0996&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0556&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;98.81%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;56.49%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;58.17%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;85.11%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.2807&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4599&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4320&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3271&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;21-day&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0223&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1233&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1218&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1340&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0136&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0708&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0651&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0793&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;98.46%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;77.16%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;78.25%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;72.80%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.2892&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.3877&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4150&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4264&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;28-day&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;RMSE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0221&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1266&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1535&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.1374&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.0133&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0706&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0857&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.0751&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;R2&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;97.76%&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;69.62%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;55.58%&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;63.62%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;MAPE&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;bold&gt;0.3095&lt;/bold&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4175&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4874&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0.4150&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>36330</offset><text>		VOC-LSTM	Vanilla_LSTM	Stacked_LSTM	Compare_GRU	 	3-day	RMSE	0.0154	0.1069	0.1075	0.1117	 	MAE	0.0084	0.0650	0.0682	0.0647	 	R2	99.65%	87.47%	87.32%	86.31%	 	MAPE	0.2255	0.3743	0.4046	0.3461	 	7-day	RMSE	0.0182	0.1019	0.1068	0.1937	 	MAE	0.0100	0.0649	0.0600	0.0986	 	R2	99.41%	88.33%	87.13%	58.78%	 	MAPE	0.2371	0.3834	0.3339	0.4329	 	14-day	RMSE	0.0221	0.1903	0.1859	0.1081	 	MAE	0.0135	0.0988	0.0996	0.0556	 	R2	98.81%	56.49%	58.17%	85.11%	 	MAPE	0.2807	0.4599	0.4320	0.3271	 	21-day	RMSE	0.0223	0.1233	0.1218	0.1340	 	MAE	0.0136	0.0708	0.0651	0.0793	 	R2	98.46%	77.16%	78.25%	72.80%	 	MAPE	0.2892	0.3877	0.4150	0.4264	 	28-day	RMSE	0.0221	0.1266	0.1535	0.1374	 	MAE	0.0133	0.0706	0.0857	0.0751	 	R2	97.76%	69.62%	55.58%	63.62%	 	MAPE	0.3095	0.4175	0.4874	0.4150	 	</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>37100</offset><text>At the same time, we performed the experiments of 3 days, 7 days, 14 days, 21 days and 28 days with the best VOC-LSTM model in the Indian dataset to test the effectiveness of the model in short term and long term prediction. The experimental results are shown in Table 10 . As demonstrated in the table, the determination coefficient R2 predicted by VOC-LSTM was 99.65% on day 3, 99.41% on day 7, 98.81% on day 14, 98.46% on day 21, and 97.76% on day 28. As the number of forecast days increases, VOC-DL performs better than other methods in both short term and long term forecasts. The determination coefficient R2 always remains at a relatively high level, which indicates that the model is effective in both long-term and short-term predictions.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>37850</offset><text>Overall, the VOC-LSTM model performed well in one-day and mid-and-long-term forecasts, indicating that the model is effective. In addition, the mid-and-long-term forecast has highly important guidance and reference significance for the national government to judge the turning point of the pandemic and rationally regulate the medical personnel and protective materials.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>38221</offset><text>Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>38232</offset><text>Our framework first incorporates variant information into the feature considerations of the model. Different variants have different transmission capabilities, so variant information has a more noticeable impact on the fluctuation of the epidemic. The model with variable variant features is more sensitive to changes in the epidemic, which can capture more confidential information. At the same time, we also propose a preprocessing method based on slope features. To add more helpful information to the dataset, the changing trend of the slope of daily newly confirmed cases for each VOC variant was calculated. This slope trend can be added to the dataset as an incremental feature. This paper adds slope information to the dataset as incremental features. It better reflects the fluctuating trend of the pandemic and has more substantial expressive power for the input data, thus improving the model's prediction performance.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>39162</offset><text>Like all modeling studies, our study has some limitations. For example, in the numerical results in Section 3, all of our experiments are based on the assumption that current policies will not change and that people will cooperate with preventive measures. However, the actual number of infections may fluctuate or rebound due to changes in government policy and the cooperation of citizens with prevention and control measures. In addition to policy changes, our model does not consider the impact of imported cases and the Spatio-temporal intersection of confirmed cases. Because of the limitations above, the following aspects are worthy of study in the future. Given the influence of both imported cases and the Spatio-temporal intersection of confirmed cases, we can consider using the Spatio-temporal residual network to model imported cases' time proximity, cycle, and trend characteristics. It is also practical to analyze the pandemic trend under the influence of imported cases or predict the possibilities of outbreaks in local areas in advance. In practice, auto-encoder-extreme learning machine model may be useful for future improvement of our application.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">title_1</infon><offset>40334</offset><text>Conclusion</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>40345</offset><text>We proposed a deep learning framework VOC-DL based on VOC variants and used slope feature method to preprocess the data. And three networks (LSTM, GRU and Bi-LSTM) were also used to model the COVID-19 dataset with additional VOC variant data, and then an estimation was conducted at the daily number of newly confirmed cases in five countries around the world. Experimental results show that VOC-BiLSTM has the best prediction performance for Russia after data normalization, and the determination coefficient (R2) is 98.9%. In terms of the results of VOC-GRU, it also has the best prediction performance for Russia, with the determination coefficient of 98.88%. VOC-LSTM had the best average prediction performance in all countries. The average of RMSE, MAE and MAPE were 0.0343, 0.0209 and 1.2974, respectively (smallest among all models), and the average determination coefficient R2 was 96.83% (biggest among all models). Compared with the existing methods, VOC-LSTM, VOC-GRU and VOC-BiLSTM based on VOC variants show excellent robustness and accurate prediction ability. However, VOC-LSTM outperformed all other models based on four error measures. The R2 score of VOC-LSTM improves by up to 1.3%. Meanwhile, the model performs well in both short term and long term predictions. The predicted R2 was 99.65% for 3 days, 99.41% for 7 days, 98.46% for 14 days, and 97.76% for 28 days. Compared with the other three comparison methods, the predictions of different periods are improved by 13.34%, 40.63%, 42.32%, 25.66% and 42.18%, respectively. It can be concluded that VOC-LSTM is the best predictor for such series data and has higher prediction accuracy in the long term. At the same time, our VOC-DL framework combined with VOC variants has reference significance for the predictions of other variants in the future.</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">title_1</infon><offset>42168</offset><text>Declaration of Competing Interest</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">paragraph</infon><offset>42202</offset><text>The authors declare that there is no conflict of interests.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>42262</offset><text>References</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>42273</offset><text>“Classification of Omicron (B.1.1.529): SARS-CoV-2 Variant of Concern.” https://www.who.int/news/item/26-11-2021-classification-of-omicron-(b.1.1.529)-sars-cov-2-variant-of-concern (accessed Jul. 12, 2022).</text></passage><passage><infon key="name_0">surname:Ye;given-names:Y.</infon><infon key="name_1">surname:Shi;given-names:J.</infon><infon key="name_2">surname:Zhu;given-names:D.</infon><infon key="name_3">surname:Su;given-names:L.</infon><infon key="name_4">surname:Huang;given-names:J.</infon><infon key="name_5">surname:Huang;given-names:Y.</infon><infon key="section_type">REF</infon><infon key="source">Comput. Methods Progr. Biomed.</infon><infon key="type">ref</infon><infon key="volume">209</infon><infon key="year">2021</infon><offset>42484</offset><text>Management of medical and health big data based on integrated learning-based health care system: a review and comparative analysis</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>42615</offset><text>S. Sanche, Y. T. Lin, C. Xu, E. Romero-Severson, N. W. Hengartner, and R. Ke, “The novel coronavirus, 2019-nCoV, is highly contagious and more infectious than initially estimated,” arXiv preprint arXiv:2002.03268, 2020.</text></passage><passage><infon key="fpage">282</infon><infon key="lpage">292</infon><infon key="name_0">surname:Li;given-names:L.</infon><infon key="pub-id_pmid">32292868</infon><infon key="section_type">REF</infon><infon key="source">Infect. Dis. Model.</infon><infon key="type">ref</infon><infon key="volume">5</infon><infon key="year">2020</infon><offset>42839</offset><text>Propagation analysis and prediction of the COVID-19</text></passage><passage><infon key="comment">Feb.</infon><infon key="name_0">surname:López;given-names:L.</infon><infon key="name_1">surname:Rodó;given-names:X.</infon><infon key="pub-id_doi">10.1016/j.rinp.2020.103746</infon><infon key="section_type">REF</infon><infon key="source">Results Phys.</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2021</infon><offset>42891</offset><text>A modified SEIR model to predict the COVID-19 outbreak in Spain and Italy: simulating control scenarios and multi-scale epidemics</text></passage><passage><infon key="fpage">3279</infon><infon key="issue">4</infon><infon key="lpage">3294</infon><infon key="name_0">surname:Chen;given-names:Y.C.</infon><infon key="name_1">surname:Lu;given-names:P.E.</infon><infon key="name_2">surname:Chang;given-names:C.S.</infon><infon key="name_3">surname:Liu;given-names:T.H.</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Netw. Sci. Eng.</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2020</infon><offset>43021</offset><text>A time-dependent SIR model for COVID-19 with undetectable infected persons</text></passage><passage><infon key="fpage">169</infon><infon key="name_0">surname:Wangping;given-names:J.</infon><infon key="section_type">REF</infon><infon key="source">Front. Med.</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2020</infon><offset>43096</offset><text>Extended SIR prediction of the epidemics trend of COVID-19 in Italy and compared with Hunan, China</text></passage><passage><infon key="fpage">1</infon><infon key="issue">1</infon><infon key="lpage">15</infon><infon key="name_0">surname:Liao;given-names:Z.</infon><infon key="name_1">surname:Lan;given-names:P.</infon><infon key="name_2">surname:Liao;given-names:Z.</infon><infon key="name_3">surname:Zhang;given-names:Y.</infon><infon key="name_4">surname:Liu;given-names:S.</infon><infon key="pub-id_pmid">31913322</infon><infon key="section_type">REF</infon><infon key="source">Sci. Rep.</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">2020</infon><offset>43195</offset><text>TW-SIR: time-window based SIR for COVID-19 forecasts</text></passage><passage><infon key="fpage">1</infon><infon key="issue">1</infon><infon key="lpage">3</infon><infon key="name_0">surname:Panovska-Griffiths;given-names:J.</infon><infon key="section_type">REF</infon><infon key="source">BioMed Cent.</infon><infon key="type">ref</infon><infon key="volume">20</infon><infon key="year">2020</infon><offset>43248</offset><text>Can mathematical modelling solve the current Covid-19 crisis?</text></passage><passage><infon key="name_0">surname:Shastri;given-names:S.</infon><infon key="name_1">surname:Singh;given-names:K.</infon><infon key="name_2">surname:Kumar;given-names:S.</infon><infon key="name_3">surname:Kour;given-names:P.</infon><infon key="name_4">surname:Mansotra;given-names:V.</infon><infon key="section_type">REF</infon><infon key="source">Chaos Solitons Fractals</infon><infon key="type">ref</infon><infon key="volume">140</infon><infon key="year">2020</infon><offset>43310</offset><text>Time series forecasting of Covid-19 using deep learning models: India-USA comparative case study</text></passage><passage><infon key="name_0">surname:Zeroual;given-names:A.</infon><infon key="name_1">surname:Harrou;given-names:F.</infon><infon key="name_2">surname:Dairi;given-names:A.</infon><infon key="name_3">surname:Sun;given-names:Y.</infon><infon key="section_type">REF</infon><infon key="source">Chaos Solitons Fractals</infon><infon key="type">ref</infon><infon key="volume">140</infon><infon key="year">2020</infon><offset>43407</offset><text>Deep learning methods for forecasting COVID-19 time-series data: a comparative study</text></passage><passage><infon key="name_0">surname:Arora;given-names:P.</infon><infon key="name_1">surname:Kumar;given-names:H.</infon><infon key="name_2">surname:Panigrahi;given-names:B.K.</infon><infon key="section_type">REF</infon><infon key="source">Chaos Solitons Fractals</infon><infon key="type">ref</infon><infon key="volume">139</infon><infon key="year">2020</infon><offset>43492</offset><text>Prediction and analysis of COVID-19 positive cases using deep learning models: a descriptive case study of India</text></passage><passage><infon key="name_0">surname:Wang;given-names:P.</infon><infon key="name_1">surname:Zheng;given-names:X.</infon><infon key="name_2">surname:Ai;given-names:G.</infon><infon key="name_3">surname:Liu;given-names:D.</infon><infon key="name_4">surname:Zhu;given-names:B.</infon><infon key="section_type">REF</infon><infon key="source">Chaos Solitons Fractals</infon><infon key="type">ref</infon><infon key="volume">140</infon><infon key="year">2020</infon><offset>43605</offset><text>Time series prediction for the epidemic trends of COVID-19 using the improved LSTM deep learning method: case studies in Russia, Peru and Iran</text></passage><passage><infon key="name_0">surname:Liao;given-names:Z.</infon><infon key="name_1">surname:Lan;given-names:P.</infon><infon key="name_2">surname:Fan;given-names:X.</infon><infon key="name_3">surname:Kelly;given-names:B.</infon><infon key="name_4">surname:Innes;given-names:A.</infon><infon key="name_5">surname:Liao;given-names:Z.</infon><infon key="section_type">REF</infon><infon key="source">Comput. Biol. Med.</infon><infon key="type">ref</infon><infon key="volume">138</infon><infon key="year">2021</infon><offset>43748</offset><text>SIRVD-DL: a COVID-19 deep learning prediction model based on time-dependent SIRVD</text></passage><passage><infon key="fpage">645</infon><infon key="lpage">664</infon><infon key="name_0">surname:Ketu;given-names:S.</infon><infon key="name_1">surname:Mishra;given-names:P.K.</infon><infon key="pub-id_pmid">34815733</infon><infon key="section_type">REF</infon><infon key="source">Soft Comput.</infon><infon key="type">ref</infon><infon key="volume">26</infon><infon key="year">2022</infon><offset>43830</offset><text>India perspective: CNN-LSTM hybrid deep learning model-based COVID-19 prediction and current status of medical resource availability</text></passage><passage><infon key="comment">Jan.</infon><infon key="fpage">335</infon><infon key="lpage">344</infon><infon key="name_0">surname:Alassafi;given-names:M.O.</infon><infon key="name_1">surname:Jarrah;given-names:M.</infon><infon key="name_2">surname:Alotaibi;given-names:R.</infon><infon key="pub-id_doi">10.1016/j.neucom.2021.10.035</infon><infon key="pub-id_pmid">34690432</infon><infon key="section_type">REF</infon><infon key="source">Neurocomputing</infon><infon key="type">ref</infon><infon key="volume">468</infon><infon key="year">2022</infon><offset>43963</offset><text>Time series predicting of COVID-19 based on deep learning</text></passage><passage><infon key="fpage">276</infon><infon key="issue">2</infon><infon key="lpage">288</infon><infon key="name_0">surname:Wang;given-names:H.</infon><infon key="pub-id_doi">10.1109/JSTSP.2022.3152375</infon><infon key="section_type">REF</infon><infon key="source">IEEE J. Sel. Top. Signal Process.</infon><infon key="type">ref</infon><infon key="volume">16</infon><infon key="year">2022</infon><offset>44021</offset><text>Predicting the epidemics trend of COVID-19 using epidemiological-based generative adversarial networks</text></passage><passage><infon key="comment">Apr.</infon><infon key="fpage">579</infon><infon key="issue">3</infon><infon key="lpage">586</infon><infon key="name_0">surname:Ahuja;given-names:S.</infon><infon key="name_1">surname:Shelke;given-names:N.A.</infon><infon key="name_2">surname:Singh;given-names:P.K.</infon><infon key="pub-id_doi">10.1007/s11760-021-01988-1</infon><infon key="pub-id_pmid">34335985</infon><infon key="section_type">REF</infon><infon key="source">SIViP</infon><infon key="type">ref</infon><infon key="volume">16</infon><infon key="year">2022</infon><offset>44124</offset><text>A deep learning framework using CNN and stacked Bi-GRU for COVID-19 predictions in India</text></passage><passage><infon key="fpage">4287</infon><infon key="issue">8</infon><infon key="name_0">surname:Musulin;given-names:J.</infon><infon key="pub-id_pmid">33919496</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Environ. Res. Public Health</infon><infon key="type">ref</infon><infon key="volume">18</infon><infon key="year">2021</infon><offset>44213</offset><text>Application of artificial intelligence-based regression methods in the problem of covid-19 spread prediction: a systematic review</text></passage><passage><infon key="name_0">surname:Devaraj;given-names:J.</infon><infon key="section_type">REF</infon><infon key="source">Results Phys.</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2021</infon><offset>44343</offset><text>Forecasting of COVID-19 cases using deep learning models: is it reliable and practically significant?</text></passage><passage><infon key="fpage">1735</infon><infon key="issue">8</infon><infon key="lpage">1780</infon><infon key="name_0">surname:Hochreiter;given-names:S.</infon><infon key="name_1">surname:Schmidhuber;given-names:J.</infon><infon key="pub-id_pmid">9377276</infon><infon key="section_type">REF</infon><infon key="source">Neural Comput.</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">1997</infon><offset>44445</offset><text>Long short-term memory</text></passage><passage><infon key="fpage">2673</infon><infon key="issue">11</infon><infon key="lpage">2681</infon><infon key="name_0">surname:Schuster;given-names:M.</infon><infon key="name_1">surname:Paliwal;given-names:K.K.</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Signal Process.</infon><infon key="type">ref</infon><infon key="volume">45</infon><infon key="year">1997</infon><offset>44468</offset><text>Bidirectional recurrent neural networks</text></passage><passage><infon key="fpage">6645</infon><infon key="lpage">6649</infon><infon key="name_0">surname:Graves;given-names:A.</infon><infon key="name_1">surname:Mohamed;given-names:A.</infon><infon key="name_2">surname:Hinton;given-names:G.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>44508</offset></passage><passage><infon key="pub-id_doi">10.48550/arXiv.1406.1078</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>44509</offset></passage><passage><infon key="name_0">surname:Nabi;given-names:K.N.</infon><infon key="name_1">surname:Tahmid;given-names:M.T.</infon><infon key="name_2">surname:Rafi;given-names:A.</infon><infon key="name_3">surname:Kader;given-names:M.E.</infon><infon key="name_4">surname:Haider;given-names:M.A.</infon><infon key="section_type">REF</infon><infon key="source">Results Phys.</infon><infon key="type">ref</infon><infon key="volume">24</infon><infon key="year">2021</infon><offset>44510</offset><text>Forecasting COVID-19 cases: a comparative analysis between recurrent and convolutional neural networks</text></passage><passage><infon key="fpage">124552</infon><infon key="name_0">surname:Tang;given-names:Zhenhao</infon><infon key="name_1">surname:Wang;given-names:Shikui</infon><infon key="name_2">surname:Chai;given-names:Xiangying</infon><infon key="name_3">surname:Cao;given-names:Shengxian</infon><infon key="name_4">surname:Ouyang;given-names:Tinghui</infon><infon key="section_type">REF</infon><infon key="source">Energy</infon><infon key="type">ref</infon><infon key="volume">256</infon><infon key="year">2022</infon><offset>44613</offset><text>Auto-encoder-extreme learning machine model for boiler NOx emission concentration prediction</text></passage></document></collection>
